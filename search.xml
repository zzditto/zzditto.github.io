<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[东北攻略]]></title>
    <url>%2F2019%2F09%2F02%2FEssays%2F%E4%B8%9C%E5%8C%97%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[起因国庆东北游 经过路线规划大连线1234st=&gt;start: 北京e=&gt;end: 北京op1=&gt;operation: 大连st-&gt;op1-&gt;e 路线和车费北京—-&gt;大连(261~400)推荐：D45车次 &emsp; 北京-大连北 &emsp;时间：6:55-13:08 &emsp;耗时：6h13分 &emsp;车费：261 大连线景点推荐 大连滨海路延绵数公里的海景公路，徒步骑行胜地 金石滩国家旅游度假区汇集娱乐休闲于一体，是个海滨度假好去处 星海公园历史悠久的开放式海滨公园，沙滩浴场，是大连市民休憩消暑的好去处 俄罗斯风情街中国第一条俄式建筑风格街道，可以淘到一些东欧特色小商品 东方威尼斯水城漫步于欧式建筑与水城风光中，感受威尼斯水城般的异域风情。 老虎滩海洋公园欣赏各种极地动物的逗趣表演，乘坐跨海索道俯瞰海滨风光。 棒棰岛大连市区环境最好的海滩，孤立于海上的棒棰岛是著名景观。 大连圣亚海洋世界在全景海底通道中感受海底世界，欣赏精彩的海豚、海象等表演。 老铁山 日落下的山顶灯塔，和泾渭分明的黄渤海交界线，是老铁山的经典去处。 大鹿岛大鹿岛到庄河的王家岛、石城岛，长海的大小长山岛、獐子岛等周边海岛。 如果都去，预计花费时间3-4天，此处按照4天计算 沈阳： 沈阳热门景点如图，想去的欲望并不大。所以从路线上看，推荐从北京直达大连，在大连逛4-5天左右，做慢火车慢慢回北京。 吉林线1234st=&gt;start: 北京e=&gt;end: 北京op1=&gt;operation: 吉林长白山st-&gt;op1-&gt;e 吉林线景点推荐 长白山天池位于长白山主峰山巅的圣洁之湖，是长白山的必赏之处。 长白山北坡观长白瀑布、漫步谷底林海，坐倒站车上主峰赏天池美景。 长白山西坡景区赏锦江大峡谷奇景和草甸山花遍野，观视野开阔的天池全貌。 长白瀑布长白山瀑布夏季轰鸣如雷，冬季一挂银川，相当壮观。 鸭绿江 望天鹅风景区 大兴安岭 推荐冬季游玩 伊春12345st=&gt;start: 北京e=&gt;end: 北京op1=&gt;operation: 哈尔滨op2=&gt;operation: 伊春st-&gt;op1-&gt;op2-&gt;e 小兴安岭—黑龙江伊春尝试过坐着火车穿越森林吗？去伊春感受一下吧，伊春每个区都有林场，很多是半原始的森林，天然氧吧。其实大兴安岭景点没有小兴安岭集中，去牙克石、博克图附近转转吧。 秋天，白桦和栎树的叶子变黄了，枫树的叶子火一样红，松柏显得更苍翠了。秋风吹来，落叶在林间飞舞。这时候，森林向人们献出了酸甜可口的山葡萄，又香又脆的榛子，鲜嫩的蘑菇和木耳，还有人参等名贵药材。 ——《美丽的小兴安岭》 伊春景点推荐 毛衫沟国家森林公园原生态的自然风光，大峡谷的风景让人惊艳。 汤旺河国家公园 黑龙江汤旺河国家公园地处小兴安岭南麓，植被覆盖率99.8%以上，以红松为主的针阔叶混交林是亚洲最完整、最具代表性的原始红松林生长地，素有“红松故乡”之美誉。 兴安森林公园 金山鹿苑 五营国家森林公园 与刘少奇主席坐过的小火车合影，登上观光塔环望浩瀚的原始林海。 茅山瀑布 小东沟原始森林 参考去哪儿网https://travel.qunar.com/p-cs300134-dalian-jingdian马蜂窝http://www.mafengwo.cn/jd/10301/gonglve.html知乎问题：作为一个南方人，我想去东北旅行，但是东北这么大，哪些地方比较好玩呀？知乎问题：国内有哪些冷门但有特色的旅游地点？]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK学习-1]]></title>
    <url>%2F2019%2F09%2F02%2FLearn%2FELK%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[ELK是什么ELK是三个工具的集合：elasticsearch + logstach + kibana，三套工具形成了一套实用，易用的监控架构，很多公司利用他来搭建可视化的海量日志分析平台 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 Logstash是一个用于管理日志和事件的工具，你可以用它去收集日志、转换日志、解析日志并将他们作为数据提供给其它模块调用，例如搜索、存储等。 Kibana是一个优秀的前端日志展示框架，它可以非常详细的将日志转化为各种图表，为用户提供强大的数据可视化支持。]]></content>
      <categories>
        <category>大数据，ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ntp自定义日志文件]]></title>
    <url>%2F2019%2F09%2F02%2FBigData%2Fntp%E8%87%AA%E5%AE%9A%E4%B9%89%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[起因在搭建好大数据平台之后，集群的两个节点的Hbase regionserver总是莫名其妙的挂掉，检查时间，发现时间和其他机器相差甚远，于是查看ntp服务，发现这两节点的ntp服务已经挂掉，但是找不到相应的日志信息，所以决定给ntpd服务指定相应的日志文件 操作查看ntp.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@vm05 ~]# cat /etc/ntp.conf# For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.restrict default nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1restrict ::1# Hosts on local network are less restricted.#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst#设置与主节点ip同步server 172.18.4.11 prefer#设置副设置与本地同步#server 127.127.1.0#fudge 127.127.1.0 stratum 10#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography.keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats# Disable the monitoring facility to prevent amplification attacks using ntpdc# monlist command when default restrict does not include the noquery flag. See# CVE-2013-5211 for more details.# Note: Monitoring will not be disabled with the limited restriction flag.disable monitor 发现并没有任何有关logs的参数配置 列出所有ntpd的配置文件1234[root@vm05 ~]# rpm -ql ntp|grep conf/etc/ntp.conf/etc/sysconfig/ntpd/usr/share/man/man5/ntp.conf.5.gz 发现除了/etc/ntp.conf,还有/etc/sysconfig/ntpd配置文件同时，查看运行状态下的ntpd服务，可以发现ntpd的启动是使用的/etc/sysconfig/ntpd 查看/etc/sysconfig/ntpd123[root@vm05 ~]# cat /etc/sysconfig/ntpd# Command line options for ntpdOPTIONS="-g" 12345678910111213[root@vm01 ~]# systemctl status ntpd● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2019-08-28 16:36:55 CST; 4 days ago Main PID: 34251 (ntpd) CGroup: /system.slice/ntpd.service └─34251 /usr/sbin/ntpd -u ntp:ntp -gAug 28 16:36:56 vm01 ntpd[34251]: Listen normally on 2 lo 127.0.0.1 UDP 123Aug 28 16:36:56 vm01 ntpd[34251]: Listen normally on 3 ens192 172.18.4.11 UDP 123Aug 28 16:36:56 vm01 ntpd[34251]: Listen normally on 4 lo ::1 UDP 123Aug 28 16:36:56 vm01 ntpd[34251]: Listening on routing socket on fd #21 for interface updatesAug 28 16:36:56 vm01 ntpd[34251]: 0.0.0.0 c016 06 restar 同时，查看ntpd的参数设置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@vm05 ~]# ntpd --helpntpd - NTP daemon program - Ver. 4.2.6p5Usage: ntpd [ -&lt;flag&gt; [&lt;val&gt;] | --&lt;name&gt;[&#123;=| &#125;&lt;val&gt;] ]... Flg Arg Option-Name Description -4 no ipv4 Force IPv4 DNS name resolution - prohibits the option 'ipv6' -6 no ipv6 Force IPv6 DNS name resolution - prohibits the option 'ipv4' -a no authreq Require crypto authentication - prohibits the option 'authnoreq' -A no authnoreq Do not require crypto authentication - prohibits the option 'authreq' -b no bcastsync Allow us to sync to broadcast servers -c Str configfile configuration file name -d no debug-level Increase output debug message level - may appear multiple times -D Str set-debug-level Set the output debug message level - may appear multiple times -f Str driftfile frequency drift file name -g no panicgate Allow the first adjustment to be Big - may appear multiple times -i Str jaildir Jail directory -I Str interface Listen on an interface name or address - may appear multiple times -k Str keyfile path to symmetric keys -l Str logfile path to the log file -L no novirtualips Do not listen to virtual interfaces -m no mlock Lock memory -n no nofork Do not fork -N no nice Run at high priority -p Str pidfile path to the PID file - may appear up to 2 times -P Num priority Process priority -q no quit Set the time and quit -r Str propagationdelay Broadcast/propagation delay Str saveconfigquit Save parsed configuration and quit -s Str statsdir Statistics file location -t Str trustedkey Trusted key number - may appear multiple times -u Str user Run as userid (or userid:groupid) - may appear up to 2 times -U Num updateinterval interval in seconds between scans for new or dropped interfaces Str var make ARG an ntp variable (RW) - may appear multiple times Str dvar make ARG an ntp variable (RW|DEF) - may appear multiple times -x no slew Slew up to 600 seconds -! opt version output version information and exit -? no help display extended usage information and exit -! no more-help extended usage information passed thru pagerOptions are specified by doubled hyphens and their name or by a singlehyphen and the flag character.The following option preset mechanisms are supported: - examining environment variables named NTPD_*Please send bug reports to: &lt;http://bugs.ntp.org, bugs@ntp.org&gt;exit 0 发现其中使用了-g的配置参数，并同时发现了-l logfile的参数所以，推出，可以通过添加logfile参数在/etc/sysconfig/ntpd 123[root@vm05 ~]# cat /etc/sysconfig/ntpd# Command line options for ntpdOPTIONS="-g -l /var/log/ntpstats/ntpd.log" 重启服务1234567891011121314[root@vm05 ~]# systemctl restart ntpd[root@vm05 log]# systemctl status ntpd● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2019-09-02 18:12:56 CST; 4s ago Process: 86272 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS) Main PID: 86273 (ntpd) CGroup: /system.slice/ntpd.service └─86273 /usr/sbin/ntpd -u ntp:ntp -g -l /var/log/ntpstats/ntpd.logSep 02 18:12:56 vm05 systemd[1]: Starting Network Time Service...Sep 02 18:12:56 vm05 ntpd[86272]: ntpd 4.2.6p5@1.2349-o Fri Apr 13 12:52:27 UTC 2018 (1)Sep 02 18:12:56 vm05 systemd[1]: Started Network Time Service.[root@vm05 log]# 可以看到ntpd的logfile参数生效查看logfile日志 12345678910111213[root@vm05 log]# cat /var/log/ntpstats/ntpd.log 2 Sep 18:12:56 ntpd[86273]: proto: precision = 0.897 usec 2 Sep 18:12:56 ntpd[86273]: 0.0.0.0 c01d 0d kern kernel time sync enabled 2 Sep 18:12:56 ntpd[86273]: ntp_io: estimated max descriptors: 1024, initial socket boundary: 16 2 Sep 18:12:56 ntpd[86273]: Listen and drop on 0 v4wildcard 0.0.0.0 UDP 123 2 Sep 18:12:56 ntpd[86273]: Listen and drop on 1 v6wildcard :: UDP 123 2 Sep 18:12:56 ntpd[86273]: Listen normally on 2 lo 127.0.0.1 UDP 123 2 Sep 18:12:56 ntpd[86273]: Listen normally on 3 ens192 172.18.4.15 UDP 123 2 Sep 18:12:56 ntpd[86273]: Listen normally on 4 lo ::1 UDP 123 2 Sep 18:12:56 ntpd[86273]: Listening on routing socket on fd #21 for interface updates 2 Sep 18:12:56 ntpd[86273]: 0.0.0.0 c016 06 restart 2 Sep 18:12:56 ntpd[86273]: 0.0.0.0 c012 02 freq_set kernel 8.687 PPM 2 Sep 18:12:58 ntpd[86273]: 0.0.0.0 c515 05 clock_sync 其他如果节点时间不正确，且ntp更新缓慢，很久都没办法和主服务器同步时，设置ntp.conf参数，调整只与主服务器同步，不与本地时间同步]]></content>
      <categories>
        <category>大数据</category>
        <category>ntp</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ntp使用教程]]></title>
    <url>%2F2019%2F08%2F30%2FBigData%2Fntp%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[ntp简介NTP（Network Time Protocol，网络时间协议）是用来使网络中的各个计算机时间同步的一种协议。它的用途是把计算机的时钟同步到世界协调时UTC，其精度在局域网内可达0.1ms，在互联网上绝大多数的地方其精度可以达到1-50ms。(1s=1000ms) NTP服务器就是利用NTP协议提供时间同步服务的。 ntp原理NTP客户端可以定时自动向NTP服务器发送请求来获取时间，NTP服务器将时间发送给客户端，。 NTP服务器的时间来源有两个 1.网络时间 2.NTP服务器自己的时间 ntp的安装使用1[root@web02 ~]# yum install ntp -y ntp配置集群中主节点：[192.168.133.3] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.restrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1restrict -6 ::1# Hosts on local network are less restricted.# -----------------------------修改部分--------------------------------------------# 允许内网其他机器同步时间restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).# 中国这边最活跃的时间服务器 : http://www.pool.ntp.org/zone/cnserver 210.72.145.44 perfer # 中国国家受时中心server 202.112.10.36 # 1.cn.pool.ntp.orgserver 59.124.196.83 # 0.asia.pool.ntp.org#此处全部注释掉#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client# allow update time by the upper server# 允许上层时间服务器主动修改本机时间restrict 210.72.145.44 nomodify notrap noqueryrestrict 202.112.10.36 nomodify notrap noqueryrestrict 59.124.196.83 nomodify notrap noquery# Undisciplined Local Clock. This is a fake driver intended for backup# and when no outside source of synchronized time is available.# 外部时间服务器不可用时，以本地时间作为时间服务server 127.127.1.0 # local clockfudge 127.127.1.0 stratum 10# ---------------------------注意修改------------------------------------------# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography.keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats 从节点：[192.168.133.4….] 123456789101112131415161718192021222324252627# the administrative functions.restrict 127.0.0.1restrict ::1# Hosts on local network are less restricted.#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst#设置与主节点ip同步server 192.168.133.3 prefer#设置副设置与本地同步server 127.127.1.0fudge 127.127.1.0 stratum 10#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client 查看ntp状态12345[root@vm50 /]# ntpq -p remote refid st t when poll reach delay offset jitter============================================================================== 120.25.115.20 10.137.53.7 2 u 5 64 67 40.484 -284697 4.681 203.107.6.88 100.107.25.114 2 u - 64 77 16.579 -284697 7.181 参数解释 位置 标志 含义 remote之前 * 响应的NTP服务器和最精确的服务器 + 响应这个查询请求的NTP服务器 blank(空格) 没有响应的NTP服务器 列表上方 remote 响应这个请求的NTP服务器的名称 refid NTP服务器使用的更高一级服务器的名称 st 正在响应请求的NTP服务器的级别 when 上一次成功请求之后到现在的秒数 poll 本地和远程服务器多少时间进行一次同步，单位秒，在一开始运行NTP的时候这个poll值会比较小，服务器同步的频率大，可以尽快调整到正确的时间范围，之后poll值会逐渐增大，同步的频率也就会相应减小 reach 用来测试能否和服务器连接，是一个八进制值，每成功连接一次它的值就会增加 delay 从本地机发送同步要求到ntp服务器的往返时间 offset 主机通过NTP时钟同步与所同步时间源的时间偏移量，单位为毫秒，offset越接近于0，主机和ntp服务器的时间越接近 jitter 统计了在特定个连续的连接数里offset的分布情况。简单地说这个数值的绝对值越小，主机的时间就越精确 查看123456789[root@vm02 ~]# timedatectl Local time: Fri 2019-08-30 22:34:34 CST Universal time: Fri 2019-08-30 14:34:34 UTC RTC time: Fri 2019-08-30 14:34:34 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yesNTP synchronized: yes RTC in local TZ: no DST active: n/a]]></content>
      <categories>
        <category>大数据</category>
        <category>ntp</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch的学习安装使用]]></title>
    <url>%2F2019%2F08%2F27%2FBigData%2Felasticsearch%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[elasticsearch简介Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。但是，Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。 Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。不过，Elasticsearch不仅仅是Lucene和全文搜索，我们还能这样去描述它：分布式的实时文件存储，每个字段都被索引并可被搜索分布式的实时分析搜索引擎可以扩展到上百台服务器，处理PB级结构化或非结构化数据 elasticsearch的安装上传，解压 1234567[root@vm03 elasticsearch-7.2.0]# pwd/opt/apps/elasticearch/elasticsearch-7.2.0[root@vm03 elasticearch]# lltotal 329668-rw-r--r--. 1 root root 336647987 Aug 27 15:35 elasticsearch-7.2.0-linux-x86_64.tar.gz-rw-r--r--. 1 root root 928732 Aug 27 15:35 elasticsearch-head-master.zip[root@vm03 elasticearch]# tar -zxvf elasticsearch-7.2.0-linux-x86_64.tar.gz 运行，出错： 1234567891011121314151617[root@vm03 bin]# ./elasticsearchfuture versions of Elasticsearch will require Java 11; your Java version from [/home/jdk1.8.0_181/jre] does not meet this requirement[2019-08-27T15:56:04,870][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [vm03] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:163) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-7.2.0.jar:7.2.0] at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-7.2.0.jar:7.2.0] at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:115) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-7.2.0.jar:7.2.0]Caused by: java.lang.RuntimeException: can not run elasticsearch as root at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:105) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:172) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.2.0.jar:7.2.0] at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) ~[elasticsearch-7.2.0.jar:7.2.0] ... 6 more 增加用户es，设置密码为123456,并给与权限 12345678[root@vm03 bin]# adduser es[root@vm03 bin]# passwd esChanging password for user es.New password:BAD PASSWORD: The password contains less than 1 uppercase lettersRetype new password:passwd: all authentication tokens updated successfully.[root@vm03 bin]# chown -R es:es /opt/apps/elasticearch/ 使用es用户启动 12[root@vm03 bin]# su es[es@vm03 bin]$ ./elasticsearch 验证 123456789101112131415161718[root@vm03 ~]# curl 'http://localhost:9200/?pretty'&#123; "name" : "vm03", "cluster_name" : "elasticsearch", "cluster_uuid" : "_emUtf4WQaOremUsXM8FCA", "version" : &#123; "number" : "7.2.0", "build_flavor" : "default", "build_type" : "tar", "build_hash" : "508c38a", "build_date" : "2019-06-20T15:54:18.811730Z", "build_snapshot" : false, "lucene_version" : "8.0.0", "minimum_wire_compatibility_version" : "6.8.0", "minimum_index_compatibility_version" : "6.0.0-beta1" &#125;, "tagline" : "You Know, for Search"&#125; 修改参数主节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104[root@vm03 config]# pwd/opt/apps/elasticearch/elasticsearch-7.2.0/config[root@vm03 config]# lltotal 40-rw-rw----. 1 es es 199 Aug 27 15:56 elasticsearch.keystore-rw-rw----. 1 es es 2831 Jun 20 23:50 elasticsearch.yml-rw-rw----. 1 es es 3524 Jun 20 23:50 jvm.options-rw-rw----. 1 es es 17170 Jun 20 23:56 log4j2.properties-rw-rw----. 1 es es 473 Jun 20 23:56 role_mapping.yml-rw-rw----. 1 es es 197 Jun 20 23:56 roles.yml-rw-rw----. 1 es es 0 Jun 20 23:56 users-rw-rw----. 1 es es 0 Jun 20 23:56 users_roles[root@vm03 config]# cat elasticsearch.yml# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#cluster.name: my-ES## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#node.name: ES-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /u01/ESdata## Path to log files:#path.logs: /u01/ESdata/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 172.18.4.13## Set a custom port for HTTP:#http.port: 9093transport.port: 9094## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is ["127.0.0.1", "[::1]"]#discovery.seed_hosts: ["vm03:9094", "vm04:9094","vm05:9094"]## Bootstrap the cluster using an initial set of master-eligible nodes:#cluster.initial_master_nodes: ["ES-1", "ES-2","ES-3"]## For more information, consult the discovery and cluster formation module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: truehttp.cors.enabled: truehttp.cors.allow-origin: "*" 123456789发送到其他节点​```shell[root@vm03 apps]# for i in &#123;4,5&#125;&gt; do&gt; scp -r ./elasticearch/ vm0$i:/opt/apps/&gt; done; 从节点主要修改：node.name: ES-network.host: 172.18.4.1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677cluster.name: my-ES## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#node.name: ES-3## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /u01/ESdata## Path to log files:#path.logs: /u01/ESdata/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 172.18.4.15## Set a custom port for HTTP:##http.port: 9200http.port: 9093transport.port: 9094## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is ["127.0.0.1", "[::1]"]##discovery.seed_hosts: ["vm03", "vm04","vm05"]discovery.seed_hosts: ["vm03:9094", "vm04:9094","vm05:9094"]## Bootstrap the cluster using an initial set of master-eligible nodes:#cluster.initial_master_nodes: ["ES-1", "ES-2","ES-3"]## For more information, consult the discovery and cluster formation module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: truehttp.cors.enabled: truehttp.cors.allow-origin: "*" 从节点创建文件夹，增加es用户 123456789[root@vm04 config]# mkdir /u01/ESdata[root@vm04 config]# mkdir /u01/ESdata/logs[root@vm04 config]# adduser es[root@vm04 config]# passwd esChanging password for user es.New password:BAD PASSWORD: The password contains less than 1 uppercase lettersRetype new password:passwd: all authentication tokens updated successfully. 主从节点分别设置ES储存路径的权限和分组为es,es安装包的组和权限为es 12[root@vm03 bin]# chown -R es:es /u01/ESdata/[root@vm03 bin]# chown -R es:es /opt/apps/elasticearch/ 启动1234[root@vm04 bin]# pwd/opt/apps/elasticearch/elasticsearch-7.2.0/bin[root@vm04 bin]# su es[es@vm04 bin]$ ./elasticsearch 报错： 123[2019-08-27T17:35:24,355][INFO ][o.e.b.BootstrapChecks ] [ES-2] bound or publishing to a non-loopback address, enforcing bootstrap checksERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决： 123456789101112131415161718[es@vm04 bin]$ exitexit[root@vm04 bin]# vi /etc/sysctl.conf[root@vm04 bin]# cat /etc/sysctl.conf# sysctl settings are defined through files in# /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/.## Vendors settings live in /usr/lib/sysctl.d/.# To override a whole file, create a new file with the same in# /etc/sysctl.d/ and put new settings there. To override# only specific settings, add a file with a lexically later# name in /etc/sysctl.d/ and put new settings there.## For more information, see sysctl.conf(5) and sysctl.d(5).vm.max_map_count=655360[root@vm04 bin]# sysctl -pvm.max_map_count = 655360 重新启动]]></content>
      <categories>
        <category>大数据</category>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka的学习安装使用]]></title>
    <url>%2F2019%2F08%2F27%2FBigData%2Fkafka%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[kafka简介kafka是什么？是一个消息中间件，消息队列。 kafka名词解释broker：安装了kafka的节点message：消息（要存储的数据）topic：主题partition：分区replica：副本&emsp;主题是由分区的，写入某主题的消息，只存在于一个分区中&emsp;一个节点的不同分区是有leader和follower的&emsp;一个数据的副本也是有leader和follower的&emsp;分区的leader和副本的leader是同一个leader&emsp;但是每一个节点都只能有一个leader&emsp;如果一个节点挂掉，且此节点的副本刚好是leader，则此副本的相应副本，本事follower则就上位成为leader&emsp;kafka有负载均衡机制，当挂掉的节点恢复，则又会恢复到一个节点只有一个leaderleader：某一个分区的管理者follower：其他分区的副本都是从从属这， 用于数据同步，如果leader挂掉，则follower上位producer：生产者，写数据consumer：消费者，读数据 消息队列的应用场景 异步处理：非核心流程异步化，提高系统响应性能 应用解耦：系统不是强耦合，消息接受者可以随意增加，而不需要修改消息发送者的代码。消息发送者的成功不依赖消息接受者（比如有些银行接口不稳定，但调用方并不需要依赖这些接口）不强依赖于非本系统的核心流程，对于非核心流程，可以放到消息队列中让消息消费者去按需消费，而不影响核心主流程最终一致性：最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制实现消息可靠发送接收、业务操作的可靠执行，要注意消息重复与幂等设计所有不保证100%不丢消息的消息队列，理论上无法实现最终一致性。广播：只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情流量削峰与流控：当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。日志处理：将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题消息通讯：消息队列一般都内置了高效的通信机制，因此也可以用于单纯的消息通讯，比如实现点对点消息队列或者聊天室等。 kafka的安装上传kafka压缩包，解压 123456789101112131415[root@vm03 kafka]# pwd/opt/apps/kafka[root@vm03 kafka]# lltotal 55876drwxr-xr-x. 6 root root 89 Jun 20 04:44 kafka_2.12-2.3.0-rw-r--r--. 1 root root 57215197 Aug 27 14:49 kafka_2.12-2.3.0.tgz[root@vm03 kafka]# cd kafka_2.12-2.3.0[root@vm03 kafka_2.12-2.3.0]# lltotal 52drwxr-xr-x. 3 root root 4096 Jun 20 04:44 bindrwxr-xr-x. 2 root root 4096 Jun 20 04:44 configdrwxr-xr-x. 2 root root 4096 Aug 27 14:50 libs-rw-r--r--. 1 root root 32216 Jun 20 04:43 LICENSE-rw-r--r--. 1 root root 337 Jun 20 04:43 NOTICEdrwxr-xr-x. 2 root root 44 Jun 20 04:44 site-docs 新建logs文件夹，作为kafka的储存路径 12345678910[root@vm03 kafka_2.12-2.3.0]# mkdir logs[root@vm03 kafka_2.12-2.3.0]# lltotal 52drwxr-xr-x. 3 root root 4096 Jun 20 04:44 bindrwxr-xr-x. 2 root root 4096 Jun 20 04:44 configdrwxr-xr-x. 2 root root 4096 Aug 27 14:50 libs-rw-r--r--. 1 root root 32216 Jun 20 04:43 LICENSEdrwxr-xr-x. 2 root root 6 Aug 27 14:50 logs-rw-r--r--. 1 root root 337 Jun 20 04:43 NOTICEdrwxr-xr-x. 2 root root 44 Jun 20 04:44 site-docs 修改kafka的参数 12345678910111213141516171819202122232425262728293031323334[root@vm03 kafka_2.12-2.3.0]# cd config/[root@vm03 config]# lltotal 68-rw-r--r--. 1 root root 906 Jun 20 04:43 connect-console-sink.properties-rw-r--r--. 1 root root 909 Jun 20 04:43 connect-console-source.properties-rw-r--r--. 1 root root 5321 Jun 20 04:43 connect-distributed.properties-rw-r--r--. 1 root root 883 Jun 20 04:43 connect-file-sink.properties-rw-r--r--. 1 root root 881 Jun 20 04:43 connect-file-source.properties-rw-r--r--. 1 root root 1552 Jun 20 04:43 connect-log4j.properties-rw-r--r--. 1 root root 2262 Jun 20 04:43 connect-standalone.properties-rw-r--r--. 1 root root 1221 Jun 20 04:43 consumer.properties-rw-r--r--. 1 root root 4727 Jun 20 04:43 log4j.properties-rw-r--r--. 1 root root 1925 Jun 20 04:43 producer.properties-rw-r--r--. 1 root root 6851 Jun 20 04:43 server.properties-rw-r--r--. 1 root root 1032 Jun 20 04:43 tools-log4j.properties-rw-r--r--. 1 root root 1169 Jun 20 04:43 trogdor.conf-rw-r--r--. 1 root root 1023 Jun 20 04:43 zookeeper.properties[root@vm03 config]# vi server.properties############################# Server Basics ############################## The id of the broker. This must be set to a unique integer for each broker.broker.id=0############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/opt/apps/kafka/kafka_2.12-2.3.0/logs############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=172.18.4.11:2181,172.18.4.12:2181,172.18.4.13:2181,172.18.4.14:2181,172.18.4.15:2181 发送给其他节点 1234[root@vm03 apps]# for i in &#123;4,5&#125;&gt; do&gt; scp -r /opt/apps/kafka/ vm0$i:/opt/apps/&gt; done; 分别修改其他节点的kafka的brokerid 123456789[root@vm04 config]# vi server.properties############################# Server Basics ############################## The id of the broker. This must be set to a unique integer for each broker.broker.id=1[root@vm05 config]# vi server.properties############################# Server Basics ############################## The id of the broker. This must be set to a unique integer for each broker.broker.id=2 命令启动：各节点分别启动 123[root@vm04 kafka_2.12-2.3.0]# pwd/opt/apps/kafka/kafka_2.12-2.3.0[root@vm04 kafka_2.12-2.3.0]# ./bin/kafka-server-start.sh ./config/server.properties]]></content>
      <categories>
        <category>大数据</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Azkaban的安装使用]]></title>
    <url>%2F2019%2F08%2F23%2FBigData%2FAzkaban%E7%9A%84%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[下载azkaban 的资源下载链接：https://pan.baidu.com/s/1XGSg2rBU3jJruOnGm7x1VQ 密码：thd3 上传解压12345678910111213[root@vm01 azkaban]# tar -zxvf azkaban-sql-script-2.5.0.tar.gz[root@vm01 azkaban]# unzip -o azkaban-executor-2.5.0.zip[root@vm01 azkaban]# unzip azkaban-web-2.5.0.zip[root@vm01 azkaban]# lltotal 22720drwxr-xr-x 2 root root 4096 Aug 23 17:34 azkaban-2.5.0drwxr-xr-x 7 root root 92 Dec 3 2015 azkaban-executor-2.5.0-rw-r--r-- 1 root root 11150318 Aug 23 17:33 azkaban-executor-2.5.0.zip-rw-r--r-- 1 root root 1928 Aug 23 17:33 azkaban-sql-script-2.5.0.tar.gzdrwxr-xr-x 8 root root 103 Dec 3 2015 azkaban-web-2.5.0-rw-r--r-- 1 root root 12102703 Aug 23 17:33 azkaban-web-2.5.0.zip[root@vm01 azkaban]# pwd/opt/apps/azkaban 存储库操作123456create database azkaban;grant all on azkaban.* to 'root'@'%' identified by 'Mysql_123456';grant all on azkaban.* to 'root'@'vm01' identified by 'Mysql_123456';flush privileges;use azkaban;source /opt/apps/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql; 安装ssl安全认证cd到azkaban-web目录 12345678910[root@vm01 azkaban]# cd /opt/apps/azkaban/azkaban-web-2.5.0[root@vm01 azkaban-web-2.5.0]# lltotal 8-rw-r--r-- 1 root root 105 Apr 22 2014 azkaban.versiondrwxr-xr-x 2 root root 112 Dec 3 2015 bindrwxr-xr-x 2 root root 57 Dec 3 2015 confdrwxr-xr-x 2 root root 6 Apr 22 2014 extlibdrwxr-xr-x 2 root root 4096 Dec 3 2015 libdrwxr-xr-x 2 root root 6 Apr 22 2014 pluginsdrwxr-xr-x 6 root root 73 Dec 3 2015 web 执行命令： keytool -keystore keystore -alias jetty -genkey -keyalg RSA 123456789101112131415161718192021222324[root@vm01 azkaban-web-2.5.0]# keytool -keystore keystore -alias jetty -genkey -keyalg RSAEnter keystore password:azkabanRe-enter new password:What is your first and last name? [Unknown]:What is the name of your organizational unit? [Unknown]:What is the name of your organization? [Unknown]:What is the name of your City or Locality? [Unknown]:What is the name of your State or Province? [Unknown]:What is the two-letter country code for this unit? [Unknown]:Is CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct? [no]: YEnter key password for &lt;jetty&gt; (RETURN if same as keystore password):Re-enter new password:Warning:The JKS keystore uses a proprietary format. It is recommended to migrate to PKCS12 which is an industry standard format using "keytool -importkeystore -srckeystore keystore -destkeystore keystore -deststoretype pkcs12". 设置时区为beijing/shanghai如果时区准确就不用设置了 查看： 12[root@vm01 azkaban-web-2.5.0]# date -RFri, 23 Aug 2019 17:52:36 +0800 +0800:东八区-0800:西八区 设置： tzselect]]></content>
      <categories>
        <category>大数据</category>
        <category>Azkaban</category>
      </categories>
      <tags>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[政府外网大数据平台安装记录]]></title>
    <url>%2F2019%2F08%2F22%2FWork%2F%E6%94%BF%E5%BA%9C%E5%A4%96%E7%BD%91%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[服务器情况简介目前5台服务器处于172段，使用政务云的服务器。无法连接外网，内网是互通的。使用59段的ip对172段的进行映射，然后外部使用工具连接59段，进而控制172段的某台节点。再使用此节点免密登录其他机器进行控制。 特别之处自定义yum源使用4.11作为主服务器，并且自定义为yum源，使集群内网环境yum安装直接连接4.11的自定义yum，这些安装包提前都已下载好了，方法详见：http://www.zzditto.cn/2019/08/19/HDP%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E5%88%B6%E4%BD%9C%E6%9C%AC%E5%9C%B0yum%E6%BA%90/ 主服务器的local_yum.repo设置为： 123456[root@vm01 yum.repos.d]# cat local_yum.repo[local_yum]name=CentOS-Localbaseurl=file:///var/www/html/local_yumgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 其他服务器的local_yum.repo设置为： 123456[root@vm02 yum.repos.d]# cat local_yum.repo[local_yum]name=CentOS-Localbaseurl=http://172.18.4.11/local_yum/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 注：web浏览器无法访问172段，但是可以通过59段映射访问。但在集群内部设置地址时，应设置为集群内部可以访问的地址，即172段地址。 自定义HDP源设置同上，对于其他节点。设置地址时，设置为内部访问的地址，即172地址。 mysql原本安装的mysql服务。只安装了client和server，缺少lib和common。卸载重装，结果在删除的时候，删除了mysql.sock。安装之后无法打开。正确步骤：安装mysql服务安装mariadb服务 安装mysql出现，公匙检查不通过 12345678910Total 94 MB/s | 31 MB 00:00:00Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7The GPG keys listed for the "CentOS-Local" repository are already installed but they are not correct for this package.Check that the correct key URLs are configured for this repository. Failing package is: mysql-community-libs-compat-5.7.27-1.el7.x86_64 GPG Keys are configured as: file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 解决：使用 yum install xxx.rpm –nogpgcheck跳过公钥检查 1[root@vm02 mysql]# yum -y install mysql --nogpgcheck 安装成功后，启动mysql服务： 12[root@vm02 mysql]# systemctl start mysqldFailed to start mysqld.service: Unit not found. 启动失败，需要安装mariadb-server服务 123[root@vm02 mysql]# yum -y install mariadb-server --nogpgcheck[root@vm02 mysql]# systemctl start mysqld 启动成功 mysql执行命令1234567891011121314151617181920212223242526272829303132333435CREATE DATABASE ambari; use ambari; CREATE USER 'ambari'@'%' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'%'; CREATE USER 'ambari'@'localhost' IDENTIFIED BY 'Mysql_123456';GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'localhost'; CREATE USER 'ambari'@'master' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'master'; FLUSH PRIVILEGES; source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql show tables; use mysql; select Host,User Password from user where user='ambari'; CREATE DATABASE hive; use hive; CREATE USER 'hive'@'%' IDENTIFIED BY 'Mysql_123456';GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%'; CREATE USER 'hive'@'localhost' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'hive'@'localhost'; CREATE USER 'hive'@'master' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'hive'@'master'; FLUSH PRIVILEGES; CREATE DATABASE oozie; use oozie; CREATE USER 'oozie'@'%' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'%'; CREATE USER 'oozie'@'localhost' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'localhost';CREATE USER 'oozie'@'master' IDENTIFIED BY 'Mysql_123456'; GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'master';FLUSH PRIVILEGES; ambari-server setup123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@vm01 mysql-connector-java-5.1.47]# ambari-server setupUsing python /usr/bin/pythonSetup ambari-serverChecking SELinux...SELinux status is 'disabled'Customize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):Adjusting ambari-server permissions and ownership...Checking firewall status...Checking JDK...[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7[3] Custom JDK==============================================================================Enter choice (1): 3WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.Path to JAVA_HOME: /home/jdk1.8.0_181Validating JDK on Ambari Server...done.Checking GPL software agreement...GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.htmlEnable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? yCompleting setup...Configuring database...Enter advanced database configuration [y/n] (n)? yConfiguring database...==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle[3] - MySQL / MariaDB[4] - PostgreSQL[5] - Microsoft SQL Server (Tech Preview)[6] - SQL Anywhere[7] - BDB==============================================================================Enter choice (1): 3Hostname (localhost): vm01Port (3306):Database name (ambari):Username (ambari):Enter Database Password (bigdata):bigdataConfiguring ambari database...Configuring remote database connection properties...WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sqlProceed with configuring remote database connection properties [y/n] (y)? yExtracting system views...ambari-admin-2.6.2.2.1.jar...........Adjusting ambari-server permissions and ownership...Ambari Server 'setup' completed successfully. 启动ambari-server出错查看日志： 12345678910111223 Aug 2019 11:19:23,451 ERROR [main] DBAccessorImpl:119 - Error while creating database accessorjava.sql.SQLException: Access denied for user 'ambari'@'vm01' (using password: YES) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3978) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3914) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:871) at com.mysql.jdbc.MysqlIO.proceedHandshakeWithPluggableAuthentication(MysqlIO.java:1714) at com.mysql.jdbc.MysqlIO.doHandshake(MysqlIO.java:1224) at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2199) at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2230) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2025) at com.mysql.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:778) 尝试：增加 ‘ambari’@’vm01’ 的远程登录 12345mysql&gt; grant all privileges on *.* to 'ambari'@'vm01' identified by 'Mysql_123456';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) 不能解决。猜测上面远程登录的密码应该为bigdata【即ambari设置时设置的密码，但是使用此密码报不符合此密码策略】所以，修改mysql的登录密码为Mysql_123456。然后设置ambari时密码也为Mysql_123456 12345678mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; update user set authentication_string=passworD("Mysql_123456") where user='root';Query OK, 2 rows affected, 1 warning (0.00 sec)Rows matched: 2 Changed: 2 Warnings: 1 重启mysql使用Navicat删除ambari安装时创建的数据库和mysql数据库的user数据 再重新设置ambari-server setup，ambari库设置密码为Mysql_123456 EOF occurred in violation of protocol安装过程中报错信息如下： 1234567INFO 2019-08-23 13:24:08,381 PingPortListener.py:50 - Ping port listener started on port: 8670INFO 2019-08-23 13:24:08,385 main.py:439 - Connecting to Ambari server at https://vm01:8440 (172.18.4.11)INFO 2019-08-23 13:24:08,385 NetUtil.py:70 - Connecting to https://vm01:8440/caERROR 2019-08-23 13:24:08,549 NetUtil.py:96 - EOF occurred in violation of protocol (_ssl.c:618)ERROR 2019-08-23 13:24:08,549 NetUtil.py:97 - SSLError: Failed to connect. Please check openssl library versions.Refer to: https://bugzilla.redhat.com/show_bug.cgi?id=1022468 for more details.WARNING 2019-08-23 13:24:08,550 NetUtil.py:124 - Server at https://vm01:8440 is not reachable, sleeping for 10 seconds... 解决： 12345678910By adding below config in [security] section ofvi /etc/ambari-agent/conf/ambari-agent.ini[security]force_https_protocol=PROTOCOL_TLSv1_2vi /etc/python/cert-verification.cfg[https]verify=disable 参考：https://community.hortonworks.com/questions/218070/ambari-automatic-registration-failed-step-3-confir-1.htmlhttps://my.oschina.net/aubao/blog/1920933 hdfs写spark本地读取hdfs文件时，修改主机名为59段的地址 123val session=SparkSession.builder().master("local[*]").appName(this.getClass.getSimpleName).getOrCreate() val src = session.read.textFile("hdfs://59.218.251.29:8020/test/wd.txt") src.show(20) 但是报错，因为hdfs的3个副本，在不同的服务器，无法直接相连 1219/08/23 16:34:54 WARN DFSClient: Failed to connect to /172.18.4.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further informationjava.net.ConnectException: Connection timed out: no further information 所以要想在本地测试读取hdfs文件，需要将其下载，或者在saprk-shell命令行操作 12345scala&gt; sc.textFile("hdfs://172.18.4.11:8020/test/wd.txt")res2: org.apache.spark.rdd.RDD[String] = hdfs://172.18.4.11:8020/test/wd.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:25scala&gt; res2.take(10).toListres8: List[String] = List(html,css,hello,css,spark,html,spark,hahah,hello,nihao,, css,hi,hahah,css,hi,hahah,hello,html,spark,spark,, nihao,html,word,html,word,word,hahah,hi,spark,html,, word,spark,word,hello,nihao,hi,nihao,hahah,css,nihao,, spark,html,nihao,spark,nihao,hi,hi,hahah,html,hahah,, word,hi,spark,hello,hi,spark,hello,hello,html,hi,, word,hi,hello,nihao,css,css,spark,hello,hi,spark,, hi,hi,nihao,hahah,css,hahah,hello,spark,hahah,spark,, hello,hi,css,html,css,word,word,hi,hahah,hello,, hahah,spark,html,spark,hi,hahah,hi,css,nihao,nihao,) 但在集群中可以正常运行，读取测试 namendoe启动报错： 122019-08-23 17:29:08,923 - Retrying after 10 seconds. Reason: Execution of '/usr/hdp/current/hadoop-hdfs-namenode/bin/hdfs dfsadmin -fs hdfs://vm01:8020 -safemode get | grep 'Safe mode is OFF'' returned 1. /etc/profile: line 87: [=]: command not found/etc/profile: line 87: [=]: command not found 解决： 12[hdfs@vm01 liu]$ hdfs dfsadmin -safemode leaveSafe mode is OFF]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum下载rpm以及依赖包]]></title>
    <url>%2F2019%2F08%2F19%2FBigData%2Fyum%E4%B8%8B%E8%BD%BDrpm%E4%BB%A5%E5%8F%8A%E4%BE%9D%E8%B5%96%E5%8C%85%2F</url>
    <content type="text"><![CDATA[前言yum源的存在使得linux上软件安装变的方便快捷，但在实际的生产环境中，都是内网，离线环境，无法有效的使用yum安装。所以我们需要自定义yum源，而自定的yum源的软件包可以通过以下两种方法下载。需要联网且系统应处于什么都没有安装的阶段，防止某些依赖包不被下载下来。 Downloadonly [yum自身附带的命令]123456#下载wget示例yum install --downloadonly wgetyum install --downloadonly --downloaddir=/opt/apps/wget wget#--downloaddir=/opt/apps/wget:指定下载的目录#如果不指定，默认目录：/var/cache/yum/ 的 rhel-&#123;arch&#125;-channel/packageslocation 目录 Yumdownloader [专门的yum包下载工具，需要安装]123456789101112#安装Yumdownloader插件yum install yum-utils#下载单独的软件包yumdownloader httpd#下载软件包以及依赖包yumdownloader --resolve httpd#指定目录。如果不指定，下载目录在程序执行所在的目录yumdownloader --resolve --destdir=/root/mypackages/ httpdyumdownloader --resolve --destdir /root/mypackages/ httpd linux系统下下载mysql5.7.27安装包及其依赖示例下载 MySQL Yum Repositoryhttps://dev.mysql.com/downloads/repo/yum/注：目前mysql版本为8.0，下载此rpm，可通过编辑repo文件，获取5.7.27版本mysql 上传到linux，并安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135root@test mysql]# rpm -ivh mysql80-community-release-el7-3.noarch.rpm#可以看到含有了mysql，但是版本为8.0[root@test mysql]# yum list | grep mysqlmysql80-community-release.noarch el7-3 installedakonadi-mysql.x86_64 1.9.2-4.el7 baseapr-util-mysql.x86_64 1.5.2-6.el7 basedovecot-mysql.x86_64 1:2.2.36-3.el7 basefreeradius-mysql.x86_64 3.0.13-10.el7_6 updateslibdbi-dbd-mysql.x86_64 0.8.3-16.el7 basemysql-community-client.i686 8.0.17-1.el7 mysql80-communitymysql-community-client.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-common.i686 8.0.17-1.el7 mysql80-communitymysql-community-common.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-devel.i686 8.0.17-1.el7 mysql80-communitymysql-community-devel.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-embedded-compat.i686 8.0.17-1.el7 mysql80-communitymysql-community-embedded-compat.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-libs.i686 8.0.17-1.el7 mysql80-communitymysql-community-libs.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-libs-compat.i686 8.0.17-1.el7 mysql80-communitymysql-community-libs-compat.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-release.noarch el7-5 mysql-connectors-communitymysql-community-server.x86_64 8.0.17-1.el7 mysql80-communitymysql-community-test.x86_64 8.0.17-1.el7 mysql80-communitymysql-connector-c++.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-c++-debuginfo.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-c++-devel.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-c++-jdbc.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-java.noarch 1:5.1.25-3.el7 basemysql-connector-odbc.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-odbc-debuginfo.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-odbc-setup.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-python.noarch 2.0.4-1.el7 mysql-connectors-communitymysql-connector-python.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-python-cext.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-python-debuginfo.x86_64 2.1.7-1.el7 mysql-connectors-communitymysql-ref-manual-8.0-en-html-chapter.noarch 1-20190627 mysql80-communitymysql-ref-manual-8.0-en-pdf.noarch 1-20190627 mysql80-communitymysql-router.x86_64 8.0.12-1.el7 mysql-tools-communitymysql-router-community.x86_64 8.0.17-1.el7 mysql-tools-communitymysql-router-debuginfo.x86_64 8.0.12-1.el7 mysql-tools-communitymysql-shell.x86_64 8.0.17-1.el7 mysql-tools-communitymysql-shell-debuginfo.x86_64 8.0.17-1.el7 mysql-tools-communitymysql-utilities.noarch 1.6.5-1.el7 mysql-tools-communitymysql-utilities-extra.noarch 1.5.6-1.el7 mysql-tools-communitymysql-workbench-community.x86_64 8.0.17-1.el7 mysql-tools-communitymysql-workbench-community-debuginfo.x86_64 8.0.17-1.el7 mysql-tools-communitypcp-pmda-mysql.x86_64 4.1.0-5.el7_6 updatesphp-mysql.x86_64 5.4.16-46.el7 basephp-mysqlnd.x86_64 5.4.16-46.el7 baseqt-mysql.i686 1:4.8.7-3.el7_6 updatesqt-mysql.x86_64 1:4.8.7-3.el7_6 updatesqt5-qtbase-mysql.i686 5.9.2-3.el7 baseqt5-qtbase-mysql.x86_64 5.9.2-3.el7 baseredland-mysql.x86_64 1.0.16-6.el7 basersyslog-mysql.x86_64 8.24.0-34.el7 base[root@test mysql]# vi /etc/yum.repos.d/mysql-community.repo# Enable to use MySQL 5.5[mysql55-community]name=MySQL 5.5 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.5-community/el/7/$basearch/enabled=0gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/7/$basearch/enabled=0gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.7# enabled = 1[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# enabled = 0[mysql80-community]name=MySQL 8.0 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-8.0-community/el/7/$basearch/enabled=0gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql[mysql-connectors-community]name=MySQL Connectors Communitybaseurl=http://repo.mysql.com/yum/mysql-connectors-community/el/7/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql[root@test mysql]# yum clean all[root@test mysql]# yum repolist#可以看到，大部分已经变为5.7版本[root@test mysql]# yum list | grep mysqlmysql80-community-release.noarch el7-3 installedakonadi-mysql.x86_64 1.9.2-4.el7 baseapr-util-mysql.x86_64 1.5.2-6.el7 basedovecot-mysql.x86_64 1:2.2.36-3.el7 basefreeradius-mysql.x86_64 3.0.13-10.el7_6 updateslibdbi-dbd-mysql.x86_64 0.8.3-16.el7 basemysql-community-client.i686 5.7.27-1.el7 mysql57-communitymysql-community-client.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-common.i686 5.7.27-1.el7 mysql57-communitymysql-community-common.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-devel.i686 5.7.27-1.el7 mysql57-communitymysql-community-devel.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-embedded.i686 5.7.27-1.el7 mysql57-communitymysql-community-embedded.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-embedded-compat.i686 5.7.27-1.el7 mysql57-communitymysql-community-embedded-compat.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-embedded-devel.i686 5.7.27-1.el7 mysql57-communitymysql-community-embedded-devel.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-libs.i686 5.7.27-1.el7 mysql57-communitymysql-community-libs.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-libs-compat.i686 5.7.27-1.el7 mysql57-communitymysql-community-libs-compat.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-release.noarch el7-5 mysql-connectors-communitymysql-community-server.x86_64 5.7.27-1.el7 mysql57-communitymysql-community-test.x86_64 5.7.27-1.el7 mysql57-communitymysql-connector-c++.x86_64 8.0.17-1.el7 mysql-connectors-communitymysql-connector-c++-debuginfo.x86_64 8.0.17-1.el7 mysql-connectors-community# 下载其安装包和依赖包[root@test mysql]# yum install --downloadonly --downloaddir=/opt/apps/mysql mysql-community-server.x86_64]]></content>
      <categories>
        <category>大数据</category>
        <category>HDP</category>
      </categories>
      <tags>
        <tag>HDP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDP离线安装制作本地yum源]]></title>
    <url>%2F2019%2F08%2F19%2FBigData%2FHDP%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E5%88%B6%E4%BD%9C%E6%9C%AC%E5%9C%B0yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[前言YUM 源可以简化在 Linux 上安装软件的过程，但是生产环境通常无法上网，不能连接外网的 YUM 源，所以就无法使用 YUM 命令安装软件了。为了在内网中也可以使用 YUM 安装相关的软件，就需要配置本地 YUM 源了。 yum源原理单独使用：将一系列需要用到的rpm包提前下载保存到某个文件夹，使用createrepo创建新的repo，创建自定义repo文件，添加路径，则就可以直接在这个路径下使用里面的安装包安装软件 集群使用：使用http工具，是的内网中的各个机器能够获取到自定义yum的机器的yum仓库地址，并自定义repo文件，添加路径，即可使用自定义yum源的安装包安装软件 制作步骤安装httpd服务： 12345678910111213141516171819202122232425262728293031323334353637383940[root@test httpd]# pwd/opt/apps/httpd[root@test httpd]# ll总用量 3100-rw-r--r--. 1 root root 105728 8月 19 15:17 apr-1.4.8-3.el7_4.1.x86_64.rpm-rw-r--r--. 1 root root 94132 8月 19 15:17 apr-util-1.5.2-6.el7.x86_64.rpm-rw-r--r--. 1 root root 2844140 8月 19 15:17 httpd-2.4.6-89.el7.centos.1.x86_64.rpm-rw-r--r--. 1 root root 92776 8月 19 15:17 httpd-tools-2.4.6-89.el7.centos.1.x86_64.rpm-rw-r--r--. 1 root root 31264 8月 19 15:17 mailcap-2.1.41-2.el7.noarch.rpm[root@test httpd]# rpm -ivh apr-1.4.8-3.el7_4.1.x86_64.rpm警告：apr-1.4.8-3.el7_4.1.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:apr-1.4.8-3.el7_4.1 ################################# [100%][root@test httpd]# rpm -ivh apr-util-1.5.2-6.el7.x86_64.rpm警告：apr-util-1.5.2-6.el7.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:apr-util-1.5.2-6.el7 ################################# [100%][root@test httpd]# rpm -ivh mailcap-2.1.41-2.el7.noarch.rpm警告：mailcap-2.1.41-2.el7.noarch.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mailcap-2.1.41-2.el7 ################################# [100%][root@test httpd]# rpm -ivh httpd-tools-2.4.6-89.el7.centos.1.x86_64.rpm警告：httpd-tools-2.4.6-89.el7.centos.1.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:httpd-tools-2.4.6-89.el7.centos.1################################# [100%][root@test httpd]# rpm -ivh httpd-2.4.6-89.el7.centos.1.x86_64.rpm警告：httpd-2.4.6-89.el7.centos.1.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:httpd-2.4.6-89.el7.centos.1 ################################# [100%][root@test httpd]# systemctl start httpd[root@test httpd]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 在httpd服务目录下创建local_yum,并网页登录监测 1234[root@test local_yum]# pwd/var/www/html/[root@test html]# mkdir local_yum 修改yum源为网易云： 12345[root@test postgresql]# yum -y install wget[root@test postgresql]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo_bak[root@test postgresql]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo[root@test postgresql]# yum clean all[root@test postgresql]# yum makecache 下载HDP安装所需的rpm及依赖包: 123456789101112[root@test local_yum]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/ntp ntp[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/postgresql postgresql[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/libmpc.so.3 libmpc[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/libmpfr.so.4 mpfr[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/redhat-lsb redhat-lsb[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/createrepo createrepo[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/gcc gcc[root@test postgresql]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/python-devel python-devel[root@test libtirpc-devel]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/libtirpc-devel libtirpc-devel[root@test libtirpc-devel]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/redhat-lsb-core redhat-lsb-core[root@test libtirpc-devel]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/mariadb mariadb[root@test local_yum]# yum install --downloadonly --downloaddir=/var/www/html/local_yum/yum-plugin-priorities yum-plugin-priorities 安装createrepo： 1234567891011121314151617181920212223[root@test local_yum]# cd createrepo/[root@test createrepo]# ll总用量 460-rw-r--r--. 1 root root 95840 8月 10 2017 createrepo-0.9.9-28.el7.noarch.rpm-rw-r--r--. 1 root root 83984 7月 4 2014 deltarpm-3.6-3.el7.x86_64.rpm-rw-r--r--. 1 root root 252528 6月 24 2016 libxml2-python-2.9.1-6.el7_2.3.x86_64.rpm-rw-r--r--. 1 root root 32084 7月 4 2014 python-deltarpm-3.6-3.el7.x86_64.rpm[root@test createrepo]# rpm -ivh deltarpm-3.6-3.el7.x86_64.rpm准备中... ################################# [100%]正在升级/安装... 1:deltarpm-3.6-3.el7 ################################# [100%][root@test createrepo]# rpm -ivh python-deltarpm-3.6-3.el7.x86_64.rpm准备中... ################################# [100%]正在升级/安装... 1:python-deltarpm-3.6-3.el7 ################################# [100%][root@test createrepo]# rpm -ivh libxml2-python-2.9.1-6.el7_2.3.x86_64.rpm准备中... ################################# [100%]正在升级/安装... 1:libxml2-python-2.9.1-6.el7_2.3 ################################# [100%][root@test createrepo]# rpm -ivh createrepo-0.9.9-28.el7.noarch.rpm准备中... ################################# [100%]正在升级/安装... 1:createrepo-0.9.9-28.el7 ################################# [100%] 制作yum本地源： 12345678910111213141516171819202122[root@test local_yum]# createrepo /var/www/html/local_yum/[root@test local_yum]# cd /etc/yum.repos.d/[root@test yum.repos.d]# ll总用量 36-rw-r--r--. 1 root root 1572 12月 1 2016 CentOS-Base.repo-rw-r--r--. 1 root root 1664 11月 23 2018 CentOS-Base.repo_bak-rw-r--r--. 1 root root 1309 11月 23 2018 CentOS-CR.repo-rw-r--r--. 1 root root 649 11月 23 2018 CentOS-Debuginfo.repo-rw-r--r--. 1 root root 314 11月 23 2018 CentOS-fasttrack.repo-rw-r--r--. 1 root root 630 11月 23 2018 CentOS-Media.repo-rw-r--r--. 1 root root 1331 11月 23 2018 CentOS-Sources.repo-rw-r--r--. 1 root root 5701 11月 23 2018 CentOS-Vault.repo[root@test yum.repos.d]# vi local_yum.repo[root@test yum.repos.d]# cat local_yum.repo[local_yum]name=CentOS-Localbaseurl=file:///var/www/html/local_yumgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7[root@test local_yum]# yum clean all[root@test local_yum]# yum repolist#local_yum的status应该不为0 其他节点的repo设置： 12345678910[root@test yum.repos.d]# vi local_yum.repo[root@test yum.repos.d]# cat local_yum.repo[local_yum]name=CentOS-Localbaseurl=http://192.168.133.11/local_yum/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7[root@test local_yum]# yum clean all[root@test local_yum]# yum repolist#local_yum的status应该不为0 http服务目录文件如下：]]></content>
      <categories>
        <category>大数据</category>
        <category>HDP</category>
      </categories>
      <tags>
        <tag>HDP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器说明]]></title>
    <url>%2F2019%2F08%2F16%2FWork%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[大数据平台服务器和数据服务器数量：8台系统：centos7语言：English系统环境: 虚拟化主机 【注意：默认安装的话，为最小化安装，最小化安装缺少mysql安装的某些组件环境】系统分区情况：&emsp;root：100G&emsp;swap: 同内存大小&emsp;home：40G&emsp;数据盘：剩余容量 web页面访问ip及端口开放 【针对5台大数据平台服务器】映射地址设置（假设）：| 服务器地址 | 映射地址 || — | — || 172.18.4.11 | 59.218.251.11 || 172.18.4.12 | 59.218.251.12 || 172.18.4.13 | || 172.18.4.14 | || 172.18.4.15 | | httpd 服务器地址 映射地址 172.18.4.11：80 59.218.251.11：80 mysql 服务器ip: port 映射 172.18.4.11：3306 59.218.251.11：3306 172.18.4.12：3306 59.218.251.12：3306 Ambari 服务器ip: port 映射 172.18.4.11:8080 59.218.251.11：8080 hdfs 服务器ip: port 映射 172.18.4.11：50070 59.218.251.11：50070 服务器ip: port 映射 172.18.4.11：8020 59.218.251.11：8020 服务器ip: port 映射 172.18.4.11：50075 59.218.251.11：50075 172.18.4.12：50075 59.218.251.12：50075 172.18.4.13：50075 172.18.4.13：50075 172.18.4.15：50075 yarn 服务器ip: port 映射 172.18.4.11：8088 59.218.251.11：8088 172.18.4.12：8088 59.218.251.12：8088 mapreduce 服务器ip: port 映射 172.18.4.11：19888 59.218.251.11：19888 172.18.4.12：19888 59.218.251.12：19888 grafara 服务器ip: port 映射 172.18.4.11：3000 59.218.251.11：3000 hbase 服务器ip: port 映射 172.18.4.11：16010 59.218.251.11：16010 服务器ip: port 映射 172.18.4.11：16020 59.218.251.11：16020 172.18.4.12：16020 59.218.251.12：16020 172.18.4.13：16020 172.18.4.14：16020 172.18.4.15：16020 服务器ip: port 映射 172.18.4.11：16030 59.218.251.11：16030 172.18.4.12：16030 59.218.251.12：16030 172.18.4.13：16030 172.18.4.14：16030 172.18.4.15：16030 spark 服务器ip: port 映射 172.18.4.11：18081 59.218.251.11：18081 服务器ip: port 映射 172.18.4.11：8042 59.218.251.11：8042 172.18.4.12：8042 59.218.251.12：8042 172.18.4.13：8042 172.18.4.14：8042 172.18.4.15：8042 服务器ip: port 映射 172.18.4.11：8088 59.218.251.11：8088 172.18.4.12：8088 59.218.251.12：8088 172.18.4.13：8088 172.18.4.14：8088 172.18.4.15：8088 solo 服务器ip: port 映射 172.18.4.11：8886 59.218.251.11：8886 172.18.4.12：8989 59.218.251.12：8989 zeppelin 服务器ip: port 映射 172.18.4.11：9995 59.218.251.11：9995 172.18.4.11：9060 59.218.251.11：9060 ranger 服务器ip: port 映射 172.18.4.11：6080 59.218.251.11：6080 redis 服务器ip: port 映射 172.18.4.11：6379 59.218.251.11：6379 172.18.4.12：6379 59.218.251.12：6379 172.18.4.13：6379 172.18.4.14：6379 172.18.4.15：6379 azkaban 服务器ip: port 映射 172.18.4.11：8443 59.218.251.11：8443 172.18.4.12：8443 59.218.251.12：8443 其他 服务器ip: port 映射 172.18.4.12：9100 59.218.251.12：9100 服务器ip: port 映射 172.18.4.12：5601 59.218.251.12：5601 3台数据服务器端口：3台服务器：80 ~ 100 ， 1234 服务器ip: port 映射 172.18.4.16：80~100,1234 172.18.4.17：80~100,1234 172.18.4.18：80~100,1234 172.18.4.253：80~100,1234 59.218.251.20：80~100,1234 注：4.20的ip目前没有服务器使用，但后续数据服务会用到，需要确保此ip无人使用，且与59段的20映射成功 数据服务器：mysql 用户：root 密码：Mysql@123456]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux添加用户]]></title>
    <url>%2F2019%2F08%2F16%2FBigData%2FLinux%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[添加用户123456789101112131415#3中方式添加用户[root@vm01 ~]# useradd -m ztgxHDP[root@vm01 ~]# adduser ztgxHDPadduser: user 'ztgxHDP' already exists#区别：useradd + 用户 不能在home文件夹创建同名文件夹[root@vm01 ~]# useradd ztgxHDPuseradd: user 'ztgxHDP' already exists#设置用户密码[root@vm01 ~]# passwd ztgxHDPChanging password for user ztgxHDP.New password:123456BAD PASSWORD: The password is shorter than 8 charactersRetype new password:123456passwd: all authentication tokens updated successfully. 删除用户123[root@vm01 ~]# userdel ztgxHDP#区别：-r 会删除此用户在home下的文件夹[root@vm01 ~]# userdel -r ztgxHDP 普通用户拥有root权限/etc/passwd 将用户名的id和id组修改为01234567[root@vm01 home]# vi /etc/passwdsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinntp:x:38:38::/etc/ntp:/sbin/nologinchrony:x:994:991::/var/lib/chrony:/sbin/nologintcpdump:x:72:72::/:/sbin/nologin#ztgxHDP:x:1000:1000::/home/ztgxHDP:/bin/bashztgxHDP:x:0:0::/home/ztgxHDP:/bin/bash /etc/sudoers1234567[root@vm03 etc]# chmod +w /etc/sudoers#### Allow root to run any commands anywhereroot ALL=(ALL) ALLztgxHDP ALL=(ALL) ALL## Allows members of the 'sys' group to run networking, software,]]></content>
      <categories>
        <category>大数据</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDP安装常见问题及解决]]></title>
    <url>%2F2019%2F08%2F14%2FBigData%2FHDP%E5%AE%89%E8%A3%85%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[Requires: redhat-lsb-core问题描述： 12345678resource_management.core.exceptions.ExecutionFailed: Execution of '/usr/bin/yum -d 0 -e 0 -y install hbase_2_6_5_0_292' returned 1. Error: Package: hadoop_2_6_5_0_292-hdfs-2.7.3.2.6.5.0-292.x86_64 (HDP-2.6.5.0) Requires: libtirpc-develError: Package: hadoop_2_6_5_0_292-2.7.3.2.6.5.0-292.x86_64 (HDP-2.6.5.0) Requires: redhat-lsb-core You could try using --skip-broken to work around the problem** Found 2 pre-existing rpmdb problem(s), 'yum check' output follows:2:postfix-2.10.1-6.el7.x86_64 has missing requires of libmysqlclient.so.18()(64bit)2:postfix-2.10.1-6.el7.x86_64 has missing requires of libmysqlclient.so.18(libmysqlclient_18)(64bit) 解决：在新的机器上下载所需的软件包 12345678910111213141516171819202122232425262728293031323334[root@test apps]# yum -y install --downloadonly --downloaddir=/opt/apps/redhat-lsb-core redhat-lsb-core[root@test redhat-lsb-core]# ll总用量 1928-rw-r--r--. 1 root root 52232 11月 12 2018 at-3.1.13-24.el7.x86_64.rpm-rw-r--r--. 1 root root 62960 4月 25 2018 avahi-libs-0.6.31-19.el7.x86_64.rpm-rw-r--r--. 1 root root 117272 7月 4 2014 bc-1.06.95-13.el7.x86_64.rpm-rw-r--r--. 1 root root 154336 4月 25 2018 cups-client-1.6.3-35.el7.x86_64.rpm-rw-r--r--. 1 root root 365828 4月 25 2018 cups-libs-1.6.3-35.el7.x86_64.rpm-rw-r--r--. 1 root root 73448 7月 4 2014 ed-1.9-4.el7.x86_64.rpm-rw-r--r--. 1 root root 262480 11月 25 2015 m4-1.4.16-10.el7.x86_64.rpm-rw-r--r--. 1 root root 250776 4月 25 2018 mailx-12.5-19.el7.x86_64.rpm-rw-r--r--. 1 root root 112768 5月 10 2018 patch-2.7.1-10.el7_5.x86_64.rpm-rw-r--r--. 1 root root 144300 8月 11 2017 psmisc-22.20-15.el7.x86_64.rpm-rw-r--r--. 1 root root 38428 3月 27 2015 redhat-lsb-core-4.1-27.el7.centos.1.x86_64.rpm-rw-r--r--. 1 root root 15616 3月 27 2015 redhat-lsb-submod-security-4.1-27.el7.centos.1.x86_64.rpm-rw-r--r--. 1 root root 265768 7月 27 2015 spax-1.5.2-13.el7.x86_64.rpm-rw-r--r--. 1 root root 31064 7月 4 2014 time-1.7-45.el7.x86_64.rpm#安装顺序如下正在安装 : avahi-libs-0.6.31-19.el7.x86_64 1/14正在安装 : 1:cups-libs-1.6.3-35.el7.x86_64 2/14正在安装 : 1:cups-client-1.6.3-35.el7.x86_64 3/14正在安装 : bc-1.06.95-13.el7.x86_64 4/14正在安装 : m4-1.4.16-10.el7.x86_64 5/14正在安装 : psmisc-22.20-15.el7.x86_64 6/14正在安装 : ed-1.9-4.el7.x86_64 7/14正在安装 : patch-2.7.1-10.el7_5.x86_64 8/14正在安装 : mailx-12.5-19.el7.x86_64 9/14正在安装 : spax-1.5.2-13.el7.x86_64 10/14正在安装 : at-3.1.13-24.el7.x86_64 11/14正在安装 : time-1.7-45.el7.x86_64 12/14正在安装 : redhat-lsb-submod-security-4.1-27.el7.centos.1.x86_64 13/14正在安装 : redhat-lsb-core-4.1-27.el7.centos.1.x86_64 14/14 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#安装代码[root@vm01 redhat-lsb-core]# rpm -ivh avahi-libs-0.6.31-19.el7.x86_64.rpmPreparing... ################################# [100%] file /usr/lib64/libavahi-client.so.3.2.9 from install of avahi-libs-0.6.31-19.el7.x86_64 conflicts with file from package avahi-libs-0.6.31-17.el7.x86_64 file /usr/lib64/libavahi-common.so.3.5.3 from install of avahi-libs-0.6.31-19.el7.x86_64 conflicts with file from package avahi-libs-0.6.31-17.el7.x86_64#说明系统中含有此软件，版本不同。卸载旧版本，安装新版本。[root@vm01 redhat-lsb-core]# rpm -e --nodeps avahi-libs-0.6.31-17.el7.x86_64[root@vm01 redhat-lsb-core]# rpm -ivh avahi-libs-0.6.31-19.el7.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:avahi-libs-0.6.31-19.el7 ################################# [100%][root@vm01 redhat-lsb-core]# rpm -ivh cups-libs-1.6.3-35.el7.x86_64.rpmPreparing... ################################# [100%] package cups-libs-1:1.6.3-35.el7.x86_64 is already installed#提示一句安装，版本相同，则不用卸载[root@vm01 redhat-lsb-core]# rpm -ivh cups-client-1.6.3-35.el7.x86_64.rpmPreparing... ################################# [100%] package cups-client-1:1.6.3-35.el7.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh bc-1.06.95-13.el7.x86_64.rpmPreparing... ################################# [100%] package bc-1.06.95-13.el7.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh m4-1.4.16-10.el7.x86_64.rpmPreparing... ################################# [100%] package m4-1.4.16-10.el7.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh psmisc-22.20-15.el7.x86_64.rpmPreparing... ################################# [100%] file /usr/bin/killall from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64 file /usr/bin/peekfd from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64 file /usr/bin/prtstat from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64 file /usr/bin/pstree from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64 file /usr/sbin/fuser from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64 file /usr/share/man/man1/fuser.1.gz from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64 file /usr/share/man/man1/peekfd.1.gz from install of psmisc-22.20-15.el7.x86_64 conflicts with file from package psmisc-22.20-11.el7.x86_64[root@vm01 redhat-lsb-core]# rpm -e --nodeps psmisc-22.20-11.el7.x86_64[root@vm01 redhat-lsb-core]# rpm -ivh psmisc-22.20-15.el7.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:psmisc-22.20-15.el7 ################################# [100%][root@vm01 redhat-lsb-core]# rpm -ivh ed-1.9-4.el7.x86_64.rpmPreparing... ################################# [100%] package ed-1.9-4.el7.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh patch-2.7.1-10.el7_5.x86_64.rpmPreparing... ################################# [100%] package patch-2.7.1-10.el7_5.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh mailx-12.5-19.el7.x86_64.rpmPreparing... ################################# [100%] file /bin/mailx from install of mailx-12.5-19.el7.x86_64 conflicts with file from package mailx-12.5-12.el7_0.x86_64 file /usr/share/man/man1/mailx.1.gz from install of mailx-12.5-19.el7.x86_64 conflicts with file from package mailx-12.5-12.el7_0.x86_64[root@vm01 redhat-lsb-core]# rpm -e --nodeps mailx-12.5-12.el7_0.x86_64[root@vm01 redhat-lsb-core]# rpm -ivh mailx-12.5-19.el7.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:mailx-12.5-19.el7 ################################# [100%][root@vm01 redhat-lsb-core]# rpm -ivh spax-1.5.2-13.el7.x86_64.rpmPreparing... ################################# [100%] package spax-1.5.2-13.el7.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh at-3.1.13-24.el7.x86_64.rpmPreparing... ################################# [100%] file /usr/sbin/atd from install of at-3.1.13-24.el7.x86_64 conflicts with file from package at-3.1.13-22.el7.x86_64 file /usr/bin/at from install of at-3.1.13-24.el7.x86_64 conflicts with file from package at-3.1.13-22.el7.x86_64 file /var/spool/at from install of at-3.1.13-24.el7.x86_64 conflicts with file from package at-3.1.13-22.el7.x86_64 file /usr/share/man/man8/atd.8.gz from install of at-3.1.13-24.el7.x86_64 conflicts with file from package at-3.1.13-22.el7.x86_64 file /var/spool/at/spool from install of at-3.1.13-24.el7.x86_64 conflicts with file from package at-3.1.13-22.el7.x86_64[root@vm01 redhat-lsb-core]# rpm -e --nodeps at-3.1.13-22.el7.x86_64[root@vm01 redhat-lsb-core]# rpm -ivh at-3.1.13-24.el7.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:at-3.1.13-24.el7 ################################# [100%][root@vm01 redhat-lsb-core]# rpm -ivh time-1.7-45.el7.x86_64.rpmPreparing... ################################# [100%] package time-1.7-45.el7.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh redhat-lsb-submod-security-4.1-27.el7.centos.1.x86_64.rpmPreparing... ################################# [100%] package redhat-lsb-submod-security-4.1-27.el7.centos.1.x86_64 is already installed[root@vm01 redhat-lsb-core]# rpm -ivh redhat-lsb-core-4.1-27.el7.centos.1.x86_64.rpmPreparing... ################################# [100%] package redhat-lsb-core-4.1-27.el7.centos.1.x86_64 is already installed [root@test libtirpc-devel]# yum -y install --downloadonly --downloaddir=/opt/apps/other libtirpc-devel [root@test libtirpc-devel]# ll 总用量 184 -rw-r--r--. 1 root root 91124 11月 12 2018 libtirpc-0.2.4-0.15.el7.x86_64.rpm -rw-r--r--. 1 root root 93048 11月 12 2018 libtirpc-devel-0.2.4-0.15.el7.x86_64.rpm #安装顺序 正在安装 : libtirpc-0.2.4-0.15.el7.x86_64 1/2 正在安装 : libtirpc-devel-0.2.4-0.15.el7.x86_64 2/2]]></content>
      <categories>
        <category>大数据</category>
        <category>HDP</category>
      </categories>
      <tags>
        <tag>HDP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDP集群卸载]]></title>
    <url>%2F2019%2F08%2F14%2FBigData%2FHDP%E9%9B%86%E7%BE%A4%E5%8D%B8%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[ambari-server stop [master]12345[root@vm110 ~]# ambari-server stopUsing python /usr/bin/pythonStopping ambari-serverWaiting for server stop...Ambari Server stopped remove [all]12[root@vm110 ~]# yum remove ambari-server[root@vm110 ~]# yum remove ambari-agent 组件 [all]1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@vm110 ~]# yum list installed | grep ambari[root@vm110 ~]# yum remove -y ambari*[root@vm110 ~]# yum remove -y smartsense*[root@vm110 ~]# yum list installed | grep hdp[root@vm110 ~]# yum remove -y hdp*[root@vm110 ~]# yum list installed | grep hdfs[root@vm110 ~]# yum -y remove ranger*[root@vm110 ~]# yum list installed | grep yarn[root@vm110 ~]# yum remove -y spark*yum remove -y hive*yum remove -y hdfs*yum remove -y yarn*yum remove -y mapreduce2*yum remove -y tez*yum remove -y hbase*yum remove -y pig*yum remove -y sqoop*yum remove -y oozie*yum remove -y zookeeper*yum remove -y falcon*yum remove -y storm*yum remove -y flume*yum remove -y accumulo*yum remove -y Ambari Infra*yum remove -y Ambari Metrics*yum remove -y Atlas*yum remove -y Kafka*yum remove -y Knox*yum remove -y Log Search*yum remove -y Ranger*yum remove -y Ranger KMS*yum remove -y SmartSense*yum remove -y Zeppelin Notebook*yum remove -y Druid*yum remove -y Mahout*yum remove -y Slider*yum remove -y atlas-metadata_2_6_5_0_292-storm-plugin 0.8.0.2.6.5.0-292yum remove -y atlas-metadata_2_6_5_0_292-sqoop-plugin 0.8.0.2.6.5.0-292yum remove -y ranger_2_6_5_0_292-yarn-plugin 0.7.0.2.6.5.0-292yum remove -y bigtop-jsvc 1.0.15-29yum remove -y spark2_2_6_5_0_292-yarn-shuffle 2.3.0.2.6.5.0-292yum remove -y ranger_2_6_5_0_292-hdfs-plugin 0.7.0.2.6.5.0-292yum remove -y ranger_2_6_5_0_292-storm-plugin 0.7.0.2.6.5.0-292yum remove -y ranger_2_6_5_0_292-kafka-plugin 0.7.0.2.6.5.0-292yum remove -y atlas-metadata_2_6_5_0_292-hive-plugin 0.8.0.2.6.5.0-292yum remove -y slider_2_6_5_0_292 0.92.0.2.6.5.0-29yum remove -y ranger_2_6_5_0_292-hbase-plugin 0.7.0.2.6.5.0-292yum remove -y ranger_2_6_5_0_292-hive-plugin 0.7.0.2.6.5.0-292yum remove -y spark_2_6_5_0_292-yarn-shuffle 1.6.3.2.6.5.0-292 删除用户123456789101112131415161718192021222324252627282930313233343536userdel nagios userdel hive userdel ambari-qa userdel hbase userdel oozie userdel hcat userdel mapred userdel hdfs userdel rrdcached userdel zookeeper userdel mysql userdel sqoop userdel puppet userdel yarn userdel tez userdel hadoop userdel knox userdel storm userdel falcon userdel flume userdel nagios userdel admin userdel postgres userdel hdfs userdel zookeeper userdel hbase userdel ams userdel spark userdel kafka userdel ranger userdel kms userdel zookeeper userdel ambari-qa userdel hdfs userdel yarn userdel mapred 删除文件夹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475rm -rf /hadoop/* rm -rf /etc/ambari* rm -rf /etc/zookeeper/ rm -rf /etc/ranger* rm -rf /etc/rc.d/init.d/ranger* rm -rf /etc/hadoop/ rm -rf /etc/hadoop/ rm -rf /etc/hbase/ rm -rf /etc/hive rm -rf /usr/hdp/ rm -rf /etc/zookeeper/ rm -rf /tmp/ambari-qa rm -rf /tmp/sqoop-ambari-qa/ rm -rf /kafka-logs/ rm -rf /var/lib/ambari* rm -rf /var/lib/hive2* rm -rf /var/run/kafka/ rm -rf /etc/flume rm -rf /etc/hive-hcatalog rm -rf /etc/hive-webhcat rm -rf /etc/phoenix rm -rf /etc/ambari-metrics-collector rm -rf /etc/ambari-metrics-monitor rm -rf /tmp/hdfs rm -rf /tmp/hcat rm -rf /etc/kafka rm -rf /etc/oozie rm -rf /etc/storm rm -rf /etc/tez rm -rf /etc/falcon rm -rf /etc/slider rm -rf /etc/pig rm -rf /etc/ranger rm -rf /var/log/hadoop rm -rf /var/log/hbase rm -rf /var/log/hive rm -rf /var/log/oozie rm -rf /var/log/sqoop rm -rf /var/log/zookeeper rm -rf /var/log/flume rm -rf /var/log/storm rm -rf /var/log/hive-hcatalog rm -rf /var/log/falcon rm -rf /var/log/webhcat rm -rf /var/log/hadoop-hdfs rm -rf /var/log/hadoop-yarn rm -rf /var/log/hadoop-mapreduce rm -rf /var/log/spark rm -rf /var/log/ranger rm -rf /usr/lib/flume rm -rf /usr/lib/storm rm -rf /var/lib/hive rm -rf /var/lib/oozie rm -rf /var/lib/zookeeper rm -rf /var/lib/flume rm -rf /var/lib/hadoop-hdfs rm -rf /var/lib/slider rm -rf /var/lib/ranger rm -rf /var/tmp/oozie rm -rf /var/tmp/sqoop rm -rf /tmp/hive rm -rf /tmp/hadoop-hdfs rm -rf /etc/sqoop rm -rf /var/log/ambari-metrics-collector rm -rf /var/log/ambari-metrics-monitor rm -rf /usr/lib/ambari-metrics-collector rm -rf /var/lib/hadoop-yarn rm -rf /var/lib/hadoop-mapreduce rm -rf /var/lib/ambari-metrics-collector rm -rf /var/log/kafka rm -rf /tmp/hadoop-yarn rm -rf /hadoop/zookeeper rm -rf /hadoop/hdfs rm -rf /kafka-logs rm -rf /etc/storm-slider-client]]></content>
      <categories>
        <category>大数据</category>
        <category>HDP</category>
      </categories>
      <tags>
        <tag>HDP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark错误记录]]></title>
    <url>%2F2019%2F08%2F13%2FBigData%2Fspark%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[lost executor问题描述: 119/08/13 14:27:26 ERROR YarnScheduler: Lost executor 7 on vm54: Slave lost 123456java.io.IOException: Connection from /192.168.200.52:52124 closed at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146) at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:108) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) 1234rg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 说明：数据量大，且代码中含有shuffle过程较多 可能原因分析： yarn资源不够 节点内存分配太少，yarn kill 了spark application rdd太大，内存资源不够 解决：增加executor内存，同时增加每个executor的cpu 解决记录： before： 123456789101112131415161718192021#! /bin/bashlist="delete replace_ETL Merge"FILE_NAME=`date -d "1 days ago" +%Y-%m-%d`for type in $list ;doecho $type/usr/hdp/current/spark2-client/bin/spark-submit \--master yarn \--name $&#123;type&#125; \--class cn.sic_credit.bigdata.update_prism.report_shareholder.report_shareholder_$&#123;type&#125; \--queue Liu \--num-executors 3 \--executor-memory 2g \--executor-cores 3 \--jars $(echo /usr/hdp/2.6.5.0-292/hbase/lib/*.jar | tr ' ' ',') \/usr/local/src/liu/update_prism_sql/ztgx3-1.0-SNAPSHOT.jar \$&#123;FILE_NAME&#125;done after: 123456789101112131415161718192021#! /bin/bashlist="delete replace_ETL Merge"FILE_NAME=`date -d "1 days ago" +%Y-%m-%d`for type in $list ;doecho $type/usr/hdp/current/spark2-client/bin/spark-submit \--master yarn \--name $&#123;type&#125; \--class cn.sic_credit.bigdata.update_prism.report_shareholder.report_shareholder_$&#123;type&#125; \--queue Liu \--num-executors 3 \--executor-memory 10g \--executor-cores 3 \--jars $(echo /usr/hdp/2.6.5.0-292/hbase/lib/*.jar | tr ' ' ',') \/usr/local/src/liu/update_prism_sql/ztgx3-1.0-SNAPSHOT.jar \$&#123;FILE_NAME&#125;done 参考：Lost executor 原因分析及解决方案-记录Spark程序运行常见错误解决方法以及优化 explode炸裂函数问题描述： 1234567891011121314151617181920212223"com_bus_risks-intellectual_property": [], "com_bus_risks-judicial_sale ": [ &#123; "notice": "大耳朵图图", "date": "2019-8-20 15:26", "executive_court": "北京丰台", "sale_object": "ztgx" &#125;, &#123; "notice": "大耳朵图图", "date": "2019-8-20 15:26", "executive_court": "北京丰台", "sale_object": "ztgx" &#125;, &#123; "notice": "大耳朵图图", "date": "2019-8-20 15:26", "executive_court": "北京丰台", "sale_object": "ztgx" &#125; ], "com_bus_risks-mortgage": [], "com_bus_risks-out_abnormal_operation": [], 如上json所示，使用spark-sql解析json文件时，可以使用sql解析，可以使用core（fastjson）解析。但是遇到jsonArray即一个json数组里面含有多个json对象的情况，这个时候，对于core来说，需要解析，就需要将其数组遍历，把数组里的json对象当成多个，在外定义stringbuffer，在里面使用+=，将多个json对象同一个key的不同的值拼接起来，后面再分别取值然后赋key。 但如果使用explode炸裂函数，这种情况就很好解决了。 123456789101112131415161718192021import org.apache.spark.sql.functions._import session.implicits._val df: DataFrame = session.read.format("json").load("file:///D:\\ZTGX\\tycdata\\new") val df1 = df.select("com_bus_risks-judicial_sale ").show(100, false) val df2 = df.select( $"com_name", $"com_credit_code", (explode($"com_bus_risks-judicial_sale ") as "judicial_sale") ) df2.show(100, false) val df3 = df2.select( $"com_name", $"com_credit_code", $"judicial_sale.notice", $"judicial_sale.date", $"judicial_sale.executive_court", $"judicial_sale.sale_object" ) df3.show(100, false) df1.show 12345678910+------------------------------------------------------------------+|com_bus_risks-judicial_sale |+------------------------------------------------------------------+|[[2019-8-20,北京丰台,大耳朵图图,ztgx]] ||[[2019-8-202,北京丰台2,大耳朵图图2,ztgx2], [2019-8-203,北京丰台3,大耳朵图图3,ztgx3]]||[] ||[] ||[] ||[[2019-8-20 15:26,北京丰台,大耳朵图图,ztgx]] |+------------------------------------------------------------------+ df2.show 12345678+------------+---------------+---------------------------------+|com_name |com_credit_code|judicial_sale |+------------+---------------+---------------------------------+|敖汉旗丰收邢玉新建材门市|- |[2019-8-20,北京丰台,大耳朵图图,ztgx] ||吴君丽-湖南省平江县 |- |[2019-8-202,北京丰台2,大耳朵图图2,ztgx2] ||吴君丽-湖南省平江县 |- |[2019-8-203,北京丰台3,大耳朵图图3,ztgx3] ||敖汉旗丰收邢玉新建材门市|- |[2019-8-20 15:26,北京丰台,大耳朵图图,ztgx]|+------------+---------------+---------------------------------+ df3.show 12345678+------------+---------------+------+---------------+---------------+-----------+|com_name |com_credit_code|notice|date |executive_court|sale_object|+------------+---------------+------+---------------+---------------+-----------+|敖汉旗丰收邢玉新建材门市|- |大耳朵图图 |2019-8-20 |北京丰台 |ztgx ||吴君丽-湖南省平江县 |- |大耳朵图图2|2019-8-202 |北京丰台2 |ztgx2 ||吴君丽-湖南省平江县 |- |大耳朵图图3|2019-8-203 |北京丰台3 |ztgx3 ||敖汉旗丰收邢玉新建材门市|- |大耳朵图图 |2019-8-20 15:26|北京丰台 |ztgx |+------------+---------------+------+---------------+---------------+-----------+]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ftp自动化流程整理]]></title>
    <url>%2F2019%2F08%2F12%2FWork%2Fftp%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[ftp数据导入整体流程 ftp数据下载，下载的为sql文件 将存于本地的sql文件上传至hdfs 执行本地的sql文件，将其导入mysql中 sqoop将mysql的数据导入hdfs 清除mysql表数据 脚本路径：/hdpdata3/updata_prism_sql/ftp_autosql文件路径：/hdpdata3/updata_prism_sql/ftp_auto/ftpFile ftp_download.sh123456789101112131415161718#!/bin/bashFILE_NAME=`date -d yesterday +%Y%m%d`mkdir /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$FILE_NAMEecho "lftp下载开始"lftp ztgx:Hb1ngh1a@47.104.145.241:22049&lt;&lt;EOFcd $FILE_NAMElcd /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$FILE_NAMEmget -c *.sqlpget -c -n 10 file.datclosebyeEOFecho "lftp下载结束" sqlPutHdfs.sh123456789#! /bin/bash#根据时间变化，改变文件夹名字，上传至hdfsFILE_NAME=`date -d "1 days ago" +%Y-%m-%d`LOCAL_FILE_NAME=`date -d "1 days ago" +%Y%m%d`sudo -u hdfs hdfs dfs -rm -r /apps/hive/warehouse/ods/ods_update_prism_sql/$FILE_NAMEsudo -u hdfs hdfs dfs -mkdir /apps/hive/warehouse/ods/ods_update_prism_sql/$FILE_NAMEsudo -u hdfs hdfs dfs -put /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$LOCAL_FILE_NAME/* /apps/hive/warehouse/ods/ods_update_prism_sql/$FILE_NAME/ date_tomysql.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#! /bin/bash#FILE_NAME=`date -d yesterday +%Y%m%d`FILE_NAME=""currentHour=$(date +%H)if [ $currentHour -eq 00 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 01 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 02 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 03 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 04 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 05 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 06 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`elif [ $currentHour -eq 07 ]then FILE_NAME=`date -d "2 days ago" +%Y%m%d`else FILE_NAME=`date -d "1 days ago" +%Y%m%d`fiecho "开始导入数据"echo $&#123;FILE_NAME&#125; annual_report 1mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/annual_report_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_abnormal_info 2mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_abnormal_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_category 3mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_category_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_change_info 4mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_change_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_check_info 5mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_check_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_equity_info 6mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_equity_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_illegal_info 7mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_illegal_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_investor 8mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_investor_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_investor_entpub 9mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_investor_entpub_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_mortgage_info 10mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_mortgage_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company_punishment_info 11mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_punishment_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; company 12mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company.sqlexitEOFecho $&#123;FILE_NAME&#125; company_staff 13mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/company_staff_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; human 14mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/human_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; mortgage_change_info 15mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/mortgage_change_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; mortgage_pawn_info 16mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/mortgage_pawn_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; mortgage_people_info 17mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/mortgage_people_info_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOFecho $&#123;FILE_NAME&#125; report_change_record 18mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;source /hdpdata3/updata_prism_sql/ftp_auto/ftpFile/$&#123;FILE_NAME&#125;/report_change_record_$&#123;FILE_NAME&#125;_000.dat.sqlexitEOF#导入结束echo "数据导入完成"; sqoop_mysql_hdfs.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#!/bin/bashFILE_NAME=""currentHour=$(date +%H)if [ $currentHour -eq 00 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 01 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 02 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 03 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 04 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 05 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 06 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 07 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`else FILE_NAME=`date -d "1 days ago" +%Y-%m-%d`fi#FILE_NAME=`date -d yesterday +%Y-%m-%d`list="annual_report company_abnormal_info company_change_info company_check_info company_equity_info company_illegal_info company_investor company_investor_entpub company_mortgage_info company_punishment_info company_staff human mortgage_change_info mortgage_pawn_info mortgage_people_info report_change_record"echo $FILE_NAMEfor table in $list;do echo $table sqoop import \ --connect jdbc:mysql://192.168.200.52/update_prism \ --username root \ --password sk7678unh \ --table $table \ --m 1 \ --delete-target-dir \ --target-dir /apps/hive/warehouse/ods/ods_update_prism/$FILE_NAME/$table \ --hive-drop-import-delims \ --fields-terminated-by '\001' \ --split-by IDdone sqoop_mysql_hdfs2.sh1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/bashFILE_NAME=""currentHour=$(date +%H)if [ $currentHour -eq 00 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 01 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 02 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 03 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 04 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 05 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 06 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`elif [ $currentHour -eq 07 ]then FILE_NAME=`date -d "2 days ago" +%Y-%m-%d`else FILE_NAME=`date -d "1 days ago" +%Y-%m-%d`fi#FILE_NAME=`date -d yesterday +%Y-%m-%d`list="company company_category"for table in $list;do echo $table sqoop import \ --connect jdbc:mysql://192.168.200.52/update_prism \ --username root \ --password sk7678unh \ --table $table \ --m 1 \ --delete-target-dir \ --target-dir /apps/hive/warehouse/ods/ods_update_prism/$FILE_NAME/$table \ --hive-drop-import-delims \ --fields-terminated-by '\001'done truncate_mysql.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#! /bin/bashecho "清空update_prism数据"mysql -uroot -psk7678unh &lt;&lt; EOFuse update_prism;truncate table annual_report;truncate table company;truncate table company_abnormal_info;truncate table company_category;truncate table company_category_20170411;truncate table company_category_code_20170411;truncate table company_change_info;truncate table company_change_info_clean;truncate table company_check_info;truncate table company_equity_info;truncate table company_illegal_info;truncate table company_investor;truncate table company_investor_entpub;truncate table company_ipr_pledge_change_info_entpub;truncate table company_ipr_pledge_reg_info_entpub;truncate table company_judicial_assistance_frozen_info;truncate table company_judicial_assistance_frozen_invalidation_info;truncate table company_judicial_assistance_frozen_keep_info;truncate table company_judicial_assistance_frozen_rem_info;truncate table company_judicial_assistance_info;truncate table company_judicial_shareholder_change_info;truncate table company_license;truncate table company_license_entpub;truncate table company_license_info_creditchina;truncate table company_liquidating_info;truncate table company_mortgage_info;truncate table company_new;truncate table company_other_info;truncate table company_punishment_info;truncate table company_punishment_info_creditchina;truncate table company_staff;truncate table human;truncate table mortgage_change_info;truncate table mortgage_pawn_info;truncate table mortgage_people_info;truncate table report_change_record;truncate table report_equity_change_info;truncate table report_out_guarantee_info;truncate table report_outbound_investment;truncate table report_shareholder;truncate table report_social_security_info;truncate table report_webinfo;truncate table tb_sxbzxr_bak;exitecho "清空完毕"EOF Azkaban任务调度ftp_download.job12type = commandcommand=/hdpdata3/updata_prism_sql/ftp_auto/ftp_download.sh sqlPutHdfs.job123type = commandcommand=sudo -u hdfs /hdpdata3/updata_prism_sql/ftp_auto/sqlPutHdfs.shdependencies=ftp_download date_toMysql.job123type = commandcommand=/hdpdata3/updata_prism_sql/ftp_auto/date_toMysql.shdependencies=sqlPutHdfs sqoop_mysql_hdfs.job123type = commandcommand=sudo -u hdfs /hdpdata3/updata_prism_sql/ftp_auto/sqoop_mysql_hdfs.shdependencies=date_toMysql sqoop_mysql_hdfs2.job123type = commandcommand=sudo -u hdfs /hdpdata3/updata_prism_sql/ftp_auto/sqoop_mysql_hdfs2.shdependencies=sqoop_mysql_hdfs truncate_mysql.job123type = commandcommand=/hdpdata3/updata_prism_sql/ftp_auto/truncate_mysql.shdependencies=sqoop_mysql_hdfs2]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kerberos学习]]></title>
    <url>%2F2019%2F08%2F11%2FBigData%2Fkerberos%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[kerberos是什么强大的身份验证和建立用户身份是Hadoop安全访问的基础。用户需要能够可靠地“识别”自己，然后在整个Hadoop集群中传播该身份。完成此操作后，这些用户可以访问资源（例如文件或目录）或与集群交互（如运行MapReduce作业）。除了用户之外，Hadoop集群资源本身（例如主机和服务）需要相互进行身份验证，以避免潜在的恶意系统或守护程序“冒充”受信任的集群组件来获取数据访问权限。 Hadoop使用Kerberos作为用户和服务的强身份验证和身份传播的基础。Kerberos是一种计算机网络认证协议，它允许某实体在非安全网络环境下通信，向另一个实体以一种安全的方式证明自己的身份。 Kerberos是第三方认证机制，其中用户和服务依赖于第三方（Kerberos服务器）来对彼此进行身份验证。 Kerberos服务器本身称为密钥分发中心或KDC。 在较高的层面上，它有三个部分： 它知道的用户和服务（称为主体）及其各自的Kerberos密码的数据库一个认证服务器（AS）执行初始认证并颁发票证授予票证（TGT）一个票据授权服务器（TGS）发出基于初始后续服务票证TGT一个用户主要来自AS请求认证。AS返回使用用户主体的Kerberos密码加密的TGT，该密码仅为用户主体和AS所知。用户主体使用其Kerberos密码在本地解密TGT，从那时起，直到ticket到期，用户主体可以使用TGT从TGS获取服务票据。服务票证允许委托人访问各种服务。 Kerberos简单来说就是一个用于安全认证第三方协议，它采用了传统的共享密钥的方式，实现了在网络环境不一定保证安全的环境下，client和server之间的通信，适用于client/server模型，由MIT开发和实现。 Kerberos服务是单点登录系统，这意味着您对于每个会话只需向服务进行一次自我验证，即可自动保护该会话过程中所有后续事务的安全。 由于每次解密TGT时群集资源（主机或服务）都无法提供密码，因此它们使用称为keytab的特殊文件，该文件包含资源主体的身份验证凭据。 Kerberos服务器控制的主机，用户和服务集称为领域。]]></content>
      <categories>
        <category>大数据</category>
        <category>kerberos</category>
      </categories>
      <tags>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache zeppelin学习]]></title>
    <url>%2F2019%2F08%2F11%2FBigData%2FApache-zeppelin%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[zeppelin是什么zeppelin是apache的一个孵化项目，是一个基于web的笔记本。Ambari平台上集成了此组件，一般来说，开发人员可以将一些开发文档，笔记记录在此组件上，供多人查阅和修改。可以使用sql，shell，scala，spark(命令行)，makedown的语法做出数据驱动，交互，协作的文档各语言可以实时执行，实时查阅结果类似于ipython notebook，可以直接在浏览器中写代码，笔记并且共享 zeppelin安装和使用基本使用界面： Create new note makedown12## test创建了test文档。设置文档类型为makedown格式 shell123%shDATE=20170902echo $DATE scala1234%spark2val one=1val two="hello"println("hello world") spark.sql12%spark2.sqlshow databases html12%angular&lt;p&gt;html语言&lt;/p&gt; zeppelin其他]]></content>
      <categories>
        <category>大数据</category>
        <category>zeppelin</category>
      </categories>
      <tags>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ranger学习]]></title>
    <url>%2F2019%2F08%2F11%2FBigData%2FRanger%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Ranger是什么Ranger是大数据领域的一个集中式安全管理框架，他可以对诸如hdfs，hive，hbase，kafka进行细粒度的权限控制。一般来说，大数据产品提供给多人使用，是需要进行权限控制的，对于数据安全，产品可靠性都是很重要的 例如：控制某个用户或者一组用户对hdfs访问的权限，读写，或者控制访问的路径控制某个用户或者一组用户对hive的表的访问权限，读写，控制到哪个数据库，哪个表，哪一列… Ranger支持的组件 Ranger权限模型Ranger的权限模型主要是由权限策略组成。权限策略分为三个方面：用户，资源，权限 用户：Ranger可以对用户进行分组，一个用户可以属于多个组。Ranger可以对用户或者组进行资源的权限控制 资源：对于不同的组件，资源有着不同的表现形式。对于HDFS来说，文件路径就是资源，对于hive来说，database，table，column都是资源 权限：Ranger可以对各个资源的读，写，访问进行控制。具体可以配置白名单，白名单排除，黑名单，黑名单排斥 在大数据集群中安装好Ranger，并进行相应的权限策略配置之后，用户访问资源就会进行Ranger的权限校验，校验流程如下： 用户请求资源，会先获取所有相关的策略，并且遍历这些策略，然后根据黑白名单去判断用户访问资源的权限。由上面流程图可以看出，黑白名单的优先级。 黑名单的优先级高于白名单 黑名单排除的优先级高于黑名单 白名单排除的优先级高于白名单 决策下发如果没有匹配到任何策略，一般情况是没有权限拒绝访问。Ranger也可以设置决策下发交给系统自身的权限控制。 Ranger架构 Ranger-adminranger-admin是基于Jersey+Spring+EclipseLink框框开发的Web服务，对外提供了Restful风格的http服务。Ranger-Admin模块同样内嵌了jsp界面，用于管理员管理用户、资源、权限等信息。同样，我们可以基于它的Restful Api来编写自己的权限管理sdk。 虽然Jersey和SpringMVC同样实现了JAX-RS(javaee6提供Java API for RESTful Web Services)规范，但是jersey更加适合构建restful风格的服务，因为它天生就是为restful而生的。EclipseLink 是 JPA(Java Persistence Api)的一种实现，是java的一个ORM框架。 Plugin那么ranger是如何实现对大数据组件的权限控制访问呢？这就和ranger实现的一个个plugin有关系了。 因为几乎所有的大数据组件都有提供一个抽象的验证接口，ranger就是根据这些接口为各个大数据组件实现了对应的plugin，plugin的工作主要是从Ranger-Admin处拉取该组件配置的所有策略，然后缓存到本地，然后当有用户来请求时提供鉴权服务。 Ranger的安装使用参考文献https://blog.csdn.net/u013332124/article/details/86360756]]></content>
      <categories>
        <category>大数据</category>
        <category>Ranger</category>
      </categories>
      <tags>
        <tag>HDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flume情况简介]]></title>
    <url>%2F2019%2F08%2F04%2FWork%2Fflume%E6%83%85%E5%86%B5%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[生产集群路径：[root@vm51 myconf]# cd /opt/apps/apache-flume-1.7.0-bin/ conf文件：[root@vm51 myconf]# cd /opt/apps/apache-flume-1.7.0-bin/conf/myconf/ avro_memory_hdfs.conf： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#192.168.200.51 avro_memory_hdfsa1.sources = r1a1.channels = c1a1.sinks = k1#sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 192.168.200.51a1.sources.r1.port = 4545#memorya1.channels = c1a1.channels.c1.type = memorya1.channels.c1.capacity = 100000a1.channels.c1.transactionCapacity = 10000a1.channels.c1.keep-alive = 30#sinksa1.sinks.k1.type = hdfsa1.sinks.k1.channel = c1#指定目录a1.sinks.k1.hdfs.path = /flume/logs/%&#123;dataType&#125;/%Y-%m-%d#文件的命名, 前缀a1.sinks.k1.hdfs.filePrefix = logs-#24h就改目录（创建目录）， （这些参数影响/flume/events/%y-%m-%d/%H%M/）a1.sinks.k1.hdfs.round = truea1.sinks.k1.hdfs.roundValue = 24a1.sinks.k1.hdfs.roundUnit = hour#目录里面有文件#------start----符合其中一个就满足---#文件滚动之前的等待时间(秒)a1.sinks.k1.hdfs.rollInterval = 2400#文件滚动的大小限制(bytes) 127Ma1.sinks.k1.hdfs.rollSize = 133169152#写入多少个event数据后滚动文件(事件个数)a1.sinks.k1.hdfs.rollCount = 0#-------end-----#100个事件就往里面写入a1.sinks.k1.hdfs.batchSize = 100#用本地时间格式化目录a1.sinks.k1.hdfs.useLocalTimeStamp = true#下沉后, 生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本a1.sinks.k1.hdfs.fileType = DataStream#操作hdfs超时时间（毫秒）a1.sinks.k1.hdfs.callTimeout = 50000 爬虫集群200路径：root@ubuntu:~# cd /opt/apps/apache-flume-1.7.0-bin/ conf：root@ubuntu:~# cd /opt/apps/apache-flume-1.7.0-bin/conf/myconf/ taildir_memory_avro2.conf： 123456789101112131415161718192021222324252627282930313233343536#192.168.1.200 taildir_memory_avroa1.sources = r1a1.channels = c1a1.sinks = k1#sourcea1.sources.r1.type = TAILDIRa1.sources.r1.channels = c1#记录偏移量路径a1.sources.r1.positionFile = /home/FlumePositionFile/taildir_position.jsona1.sources.r1.filegroups = f1#监控文件路径a1.sources.r1.filegroups.f1 = /home/data1/flume_data/tyc_data/.*.loga1.sources.r1.headers.f1.headerKey1 = value1a1.sources.r1.fileHeader = true#静态拦截器a1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type=statica1.sources.r1.interceptors.i1.key= dataTypea1.sources.r1.interceptors.i1.value=tyc_dataa1.sources.r1.interceptors.i1.preserveExisting=false#memorya1.channels = c1a1.channels.c1.type = memorya1.channels.c1.capacity = 10000a1.channels.c1.transactionCapacity = 1000#sinksa1.sinks.k1.type = avroa1.sinks.k1.channel = c1a1.sinks.k1.hostname = 192.168.200.51a1.sinks.k1.port = 4545 201路径：root@ubuntu:~# cd /opt/apps/apache-flume-1.7.0-bin/ conf：root@ubuntu:~# cd /opt/apps/apache-flume-1.7.0-bin/conf/myconf/ taildir_memory_avro2.conf： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#192.168.1.201 taildir_memory_avroa1.sources = r1 r2 r3a1.channels = c1a1.sinks = k1#source r1a1.sources.r1.type = TAILDIRa1.sources.r1.channels = c1a1.sources.r1.positionFile = /home/FlumePositionFile/taildir_position.jsona1.sources.r1.filegroups = f1a1.sources.r1.filegroups.f1 = /home/data1/flume_data/tyc_data/.*.loga1.sources.r1.headers.f1.headerKey1 = value1a1.sources.r1.fileHeader = true#静态拦截器 r1a1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type=statica1.sources.r1.interceptors.i1.key= dataTypea1.sources.r1.interceptors.i1.value=tyc_dataa1.sources.r1.interceptors.i1.preserveExisting=false#source r2a1.sources.r2.type = TAILDIRa1.sources.r2.channels = c1a1.sources.r2.positionFile = /home/FlumePositionFile/tyc_relation_data/taildir_position.jsona1.sources.r2.filegroups = f1a1.sources.r2.filegroups.f1 = /home/data1/flume_data/tyc_relation_data/.*.loga1.sources.r2.headers.f1.headerKey1 = value1a1.sources.r2.fileHeader = true#静态拦截器 r2a1.sources.r2.interceptors = i2a1.sources.r2.interceptors.i2.type=statica1.sources.r2.interceptors.i2.key= dataTypea1.sources.r2.interceptors.i2.value=tyc_relation_dataa1.sources.r2.interceptors.i2.preserveExisting=false#source r3a1.sources.r3.type = TAILDIRa1.sources.r3.channels = c1a1.sources.r3.positionFile = /home/FlumePositionFile/qcc_data/taildir_position.jsona1.sources.r3.filegroups = f1a1.sources.r3.filegroups.f1 = /home/data1/flume_data/qcc_data/.*.loga1.sources.r3.headers.f1.headerKey1 = value1a1.sources.r3.fileHeader = true#r2静态拦截器 r3a1.sources.r3.interceptors = i3a1.sources.r3.interceptors.i3.type=statica1.sources.r3.interceptors.i3.key= dataTypea1.sources.r3.interceptors.i3.value=qcc_dataa1.sources.r3.interceptors.i3.preserveExisting=false#memorya1.channels = c1a1.channels.c1.type = memorya1.channels.c1.capacity = 10000a1.channels.c1.transactionCapacity = 1000#sinksa1.sinks.k1.type = avroa1.sinks.k1.channel = c1a1.sinks.k1.hostname = 192.168.200.51a1.sinks.k1.port = 4545 运行flume后台运行：nohup ./bin/flume-ng agent -n a1 -c ./conf/ -f ./conf/myconf/avro_memory_hdfs.conf &amp; 日志路径：cd /opt/apps/apache-flume-1.7.0-bin/logs/ 查看： 123root@ubuntu:/opt/apps/apache-flume-1.7.0-bin/conf/myconf# ps -ef | grep flumeroot 1551 1 1 Jul01 ? 11:52:15 /usr/local/custom/jdk1.8.0_74/bin/java -Xms2048m -Xmx2048m -Xss256k -Xmn1g -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit -cp /opt/apps/apache-flume-1.7.0-bin/conf:/opt/apps/apache-flume-1.7.0-bin/lib/*:/lib/* -Djava.library.path= org.apache.flume.node.Application -n a1 -f ./conf/myconf/taildir_memory_avro2.confroot 17247 16911 0 22:16 pts/0 00:00:00 grep --color=auto flume kill：kill -9 1551]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统，Linux桌面系统]]></title>
    <url>%2F2019%2F08%2F01%2FBigData%2FLinux%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[操作系统英文：operating system缩写：OS 是管理计算机硬件和软件资源的计算机程序，同时也是计算机系统的内核和基石。操作系统需要处理如管理与配置内存、决定系统资源供需的优先次序、控制输入设备与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互的操作界面。 操作系统的类型非常多样，不同机器安装的操作系统可从简单到复杂，可从移动电话的嵌入式系统到超级计算机的大型操作系统。许多操作系统制造者对它涵盖范畴的定义也不尽一致，例如有些操作系统集成了图形用户界面，而有些仅使用命令行界面，而将图形用户界面视为一种非必要的应用程序。 常见操作系统Android, iOS, Linux, Windows,Mac OS X 类Unix系统类Unix系统（英文：Unix-like）指各种传统的Unix系统（比如FreeBSD、OpenBSD、SUN公司的Solaris）以及各种与传统Unix类似的系统（例如Minix、Linux、QNX等）。它们虽然有的是自由软件，有的是商业软件，但都相当程度地继承了原始UNIX的特性，有许多相似处，并且都在一定程度上遵守POSIX规范。类Unix通常指的是比原先的Unix包含更多特征的OS。 使用范围最广的是linux系统 Linux系统Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和UNIX的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的UNIX工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。Linux操作系统诞生于1991 年10 月5 日（这是第一次正式向外公布时间）。Linux存在着许多不同的Linux版本，但它们都使用了Linux内核。Linux可安装在各种计算机硬件设备中，比如手机、平板电脑、路由器、视频游戏控制台、台式计算机、大型机和超级计算机。严格来讲，Linux这个词本身只表示Linux内核，但实际上人们已经习惯了用Linux来形容整个基于Linux内核，并且使用GNU 工程各种工具和数据库的操作系统。 Linux发行版本从技术上来说，李纳斯•托瓦兹开发的 Linux 只是一个内核。内核指的是一个提供设备驱动、文件系统、进程管理、网络通信等功能的系统软件，内核并不是一套完整的操作系统，它只是操作系统的核心。一些组织或厂商将 Linux 内核与各种软件和文档包装起来，并提供系统安装界面和系统配置、设定与管理工具，就构成了 Linux 的发行版本。 在 Linux 内核的发展过程中，各种 Linux 发行版本起了巨大的作用，正是它们推动了 Linux 的应用，从而让更多的人开始关注 Linux。因此，把 Red Hat、Ubuntu、SUSE 等直接说成 Linux 其实是不确切的，它们是 Linux 的发行版本，更确切地说，应该叫作“以Linux为核心的操作系统软件包”。 Linux 的各个发行版本使用的是同一个 Linux 内核，因此在内核层不存在什么兼容性问题，每个版本有不一样的感觉，只是在发行版本的最外层（由发行商整合开发的应用）才有所体现。 Linux 的发行版本可以大体分为两类：商业公司维护的发行版本，以著名的 Red Hat 为代表；社区组织维护的发行版本，以 Debian 为代表。 Linux部分发行版本Red Hat Linux可能这是最著名的Linux版本了，Red Hat Linux已经创造了自己的品牌，越来越多的人听说过它。Red Hat在1994年创业，当时聘用了全世界500多名员工，他们都致力于开放的源代码体系。Red Hat Linux是公共环境中表现上佳的服务器。它拥有自己的公司，能向用户提供一套完整的服务，这使得它特别适合在公共网络中使用。这个版本的Linux也使用最新的内核，还拥有大多数人都需要使用的主体软件包。Red Hat Linux的安装过程也十分简单明了。它的图形安装过程提供简易设置服务器的全部信息。磁盘分区过程可以自动完成，还可以选择GUI工具完成，即使对于 Linux新手来说这些都非常简单。选择软件包的过程也与其他版本类似；用户可以选择软件包种类或特殊的软件包。系统运行起来后，用户可以从Web站点和 Red Hat那里得到充分的技术支持。我发现Red Hat是一个符合大众需求的最优版本。在服务器和桌面系统中它都工作得很好。Red Hat的唯一缺陷是带有一些不标准的内核补丁，这使得它难于按用户的需求进行定制。 Red Hat通过论坛和邮件列表提供广泛的技术支持，它还有自己公司的电话技术支持，后者对要求更高技术支持水平的集团客户更有吸引力。 Ubuntu LinuxUbuntu是一个以桌面应用为主的Linux操作系统，其名称来自非洲南部祖鲁语或豪萨语的“ubuntu”一词（译为吾帮托或乌班图），意思是“人性”、“我的存在是因为大家的存在”，是非洲传统的一种价值观，类似华人社会的“仁爱”思想。Ubuntu基于Debian发行版和unity桌面环境，与Debian的不同在于它每6个月会发布一个新版本。Ubuntu的目标在于为一般用户提供一个最新的、同时又相当稳定的主要由自由软件构建而成的操作系统。Ubuntu具有庞大的社区力量，用户可以方便地从社区获得帮助。随着云计算的流行，ubuntu推出了一个云计算环境搭建的解决方案，可以在其官方网站找到相关信息。于2012年4月26日发布最终版ubuntu 12.04，ubuntu 12.04是长期支持的版本。Red Hat Linux CentosCentOS（Community ENTerprise Operating System）是Linux发行版之一，它是来自于Red Hat Enterprise Linux依照开放源代码规定释出的源代码所编译而成。由于出自同样的源代码，因此有些要求高度稳定性的服务器以CentOS替代商业版的Red Hat Enterprise Linux使用。两者的不同，在于CentOS并不包含封闭源代码软件,CentOS 是一个基于Red Hat Linux 提供的可自由使用源代码的企业级Linux发行版本。每个版本的 CentOS都会获得十年的支持（通过安全更新方式）。新版本的 CentOS 大约每两年发行一次，而每个版本的 CentOS 会定期（大概每六个月）更新一次，以便支持新的硬件。这样，建立一个安全、低维护、稳定、高预测性、高重复性的 Linux 环境。CentOS是Community Enterprise Operating System的缩写。CentOS 是RHEL（Red Hat Enterprise Linux）源代码再编译的产物，而且在RHEL的基础上修正了不少已知的 Bug ，相对于其他 Linux 发行版，其稳定性值得信赖。 DebianDebian Project诞生于1993年8月13日，它的目标是提供一个稳定容错的Linux版本。支持Debian的不是某家公司，而是许多在其改进过程中投入了大量时间的开发人员，这种改进吸取了早期Linux的经验。Debian以其稳定性著称，虽然它的早期版本Slink有一些问题，但是它的现有版本Potato已经相当稳定了。这个版本更多的使用了 pluggable authentication modules (PAM)，综合了一些更易于处理的需要认证的软件（如winbind for Samba）。Debian的安装完全是基于文本的，对于其本身来说这不是一件坏事。但对于初级用户来说却并非这样。因为它仅仅使用fdisk 作为分区工具而没有自动分区功能，所以它的磁盘分区过程令人十分讨厌。磁盘设置完毕后，软件工具包的选择通过一个名为dselect的工具实现，但它不向用户提供安装基本工具组（如开发工具）的简易设置步骤。最后需要使用anXious工具配置X Windows，这个过程与其他版本的X Windows配置过程类似。完成这些配置后，Debian就可以使用了。Debian主要通过基于Web的论坛和邮件列表来提供技术支持。作为服务器平台，Debian提供一个稳定的环境。为了保证它的稳定性，开发者不会在其中随意添加新技术，而是通过多次测试之后才选定合适的技术加入。当前最新正式版本是Debian 6，采用的内核是Linux 2.6.32。Debian 6 第一次 包含了一个100%开源的Linux内核，这个内核中不再包含任何闭源的硬件驱动。所有的闭源软件都被隔离成单独的软件包，放到Debian软件源的 “non-free” 部分。由此，Debian用户便可以自由地选择是使用一个完全开源的系统还是添加一些闭源驱动。 SuSe总部设在德国的SuSE AG在商界已经奋斗了8年多，它一直致力于创建一个连接数据库的最佳Linux版本。为了实现这一目的，SuSE与Oracle 和IBM合作，以使他们的产品能稳定地工作。SuSE还开发了SuSE Linux eMail Server III，一个非常稳定的电子邮件群组应用。基于2.4.10内核的SuSE 7.3，在原有版本的基础上提高了易用性。安装过程通过GUI完成，磁盘分区过程也非常简单，但它没有为用户提供更多的控制和选择。在SuSE 操作系统下，可以非常方便地访问Windows磁盘，这使得两种平台之间的切换，以及使用双系统启动变得更容易。SuSE的硬件检测非常优秀，该版本在服务器和工作站上都用得很好。SuSE拥有界面友好的安装过程，还有图形管理工具，可方便地访问Windows磁盘，对于终端用户和管理员来说使用它同样方便，这使它成为了一个强大的服务器平台。 SuSE也通过基于Web的论坛提供技术支持，另外我还发现它有电话技术支持。 Linux MintLinux Mint是一个基于Ubuntu的发行版，最早于2006年由居住在爱尔兰的法国出生的IT专家Clement Lefebvre发布。最初维护一个专门为新Linux用户提供帮助，技巧和文档的Linux网站，笔者看到了开发Linux发行版的必要性，该发行版致力于解决那些技术性较强的产品的使用问题，让它们更易于使用。在他的网站上向访问者征求反馈意见之后，他继续把许多人提到的“改进的Ubuntu”或“Ubuntu完善版”的东西建立起来。注：Ubuntu就是以易用，对新手友好著称的。可想而知Mint的目标更进一步，让Linux更加的贴近了普通用户。 但是，Linux Mint不仅仅是一个具有新的应用程序和更新的桌面主题的Ubuntu。自开始以来，开发人员一直在增加各种Mint下的图形工具以提高可用性;这包括mintDesktop – 用于配置桌面环境的实用程序，mintMenu – 一个新的，优雅的菜单结构，以方便导航，mintInstall – 一个易于使用的软件安装程序，mintUpdate – 一个软件更新程序，提供了一些更突出的几个工具和数百个额外的改进。该项目还开发了很多替代的专有程序以避免一些潜在的法律版权问题，其中包括专利和专利设计的多媒体编解码器，这些编解码器在很多发行版中通常是不存在的。因此，Mint在易用性方面的声誉得到了进一步的加强，也许Linux Mint的最佳特性之一就是开发人员倾听用户的意见，并总是快速地实施好的建议。 因为Linux Mint是可以免费下载，因此该项目通过捐赠，广告和专业支持服务获得收入。它没有固定的发布时间表或者计划的功能列表，但是在每个Ubuntu长期支持版本发布几周后，可以预期Linux Mint的新版本。除Mint的MATE和Cinnamon桌面两个主要版本之外，该项目还使用包括KDE和Xfce在内的其他桌面版本构建版本。这些版本通常在两个“主要”版本几周后完成，有时可能会缺少一些主要分支中中的一些“Mint”工具和其他功能。 Mint系列的另一个版本是基于Debian稳定版分支的“Debian版”。 Linux Mint的Debian版本提供了非常稳定的基础，而桌面软件包的更新速度比Mint的“主要分支”版本更快。 Linux Mint不适用软件自由原则，也不会发布安全公告。 优点：精心整理的内部开发的“Mint”工具，数百个用户友好的增强功能，包含多媒体编解码器缺点：“社区”版本，因此可能并不总是包含最新的功能。另外，项目不会发布安全建议软件包管理： mintInstall包管理器,使用DEB包（与Ubuntu兼容）可用的版本：“主”版本（MATE和Cinnamon桌面），“社区”版本（KDE和Xfce桌面），Linux Mint“Debian”版本（MATE或Cinnamon桌面）替代选择：Ubuntu, elementary OS, Zorin OS, Lubuntu, Xubuntu, Peppermint OS MageiaMageia可能是这个列表中的最新发行版，但它的来源可以追溯到1998年7月，当时GalDuval发布了Mandrake Linux。当时它只是一个红帽Linux的分支，KDE作为默认的桌面，更完善的硬件支持和一些用户友好的功能，加上媒体的积极评论，它获得了一定的知名度。Mandrake Linux后来变成了一个商业版本，并在2010年几乎破产之前更名为Mandriva（为了避免一些与商标有关的麻烦，并纪念与巴西的Conectiva合并），最终由一家俄罗斯风险投资公司拯救了，新管理层因为巨大的开支而决定在该公司巴黎总部裁减大部分的Mandriva开发人员。在没有工作的情况下，他们决定组建一个Mageia，这个社区项目是Mandrake和Mandriva的核心延续，或许比Mandriva本身更为合理。 Mageia主要是一个桌面版本。其最受欢迎的功能是最优秀的软件应用，精良的系统管理套件（Mageia控制中心），吸引了大量志愿者贡献者以及广泛的国际化支持。它具有最简单但功能强大的系统安装程序之一，同时还可以使用KDE或GNOME桌面和全面的语言支持。而且可以来直接从桌面安装系统，无需刻录到U盘。该发行版具有良好的软件包管理功能，具有强大的命令行选项和图形化软件管理模块，可以轻松访问数千个软件包。独特的Mageia控制中心随着每个版本的不断改进，为Linux的新手提供了一个强大的工具来配置他们的计算机的任何方面，而无需使用终端命令行。 尽管Mageia自2010年9月成立以来一直处于起步阶段，但仍有人担心其是否有能力维持长期开发的工作，毕竟大部分工作是由志愿者在完成的。此外，它缺乏一些更大的Linux发行版的完善的基础架构。项目的文档也需要做一些改进，而9个月的发布周期在引起新闻和媒体兴趣方面也可以被视为一个缺点，特别是与其他使用6个月的短期开发过程的主要发行版相比。 优点：适合初学者;优秀的中央配置工具;支持数十种语言的开箱即用支持;可安装的Live镜像缺点：与Mandriva分开之后，缺乏声誉和资源，有人担心开发者没有能力长期维持开发软件包管理：使用RPM软件包，Rpmdrake（URPMI的图形前端）的URPMI包管理器可用版本：用于32位（i586）和64位（x86_64）处理器的安装DVD;可安装32位（i586）处理器的live CD Fedora虽然Fedora仅在2004年9月才正式发布，但它的起源可追溯到1995年，当时它是由Bob Young和Marc Ewing以Red Hat Linux的名义发布的。该公司的第一款产品Red Hat Linux 1.0“母亲节”在同一年发布，之后很快又进行了一些错误修复更新。 1997年，红帽公司推出了革命性的RPM软件包管理系统，具有依赖解决方案和其他先进功能，极大地促进了分发的迅速普及并超越Slackware Linux成为世界上使用最广泛的Linux发行版。在以后的几年中，红帽将按照正常的6个月发布时间表进行开发。 在2003年刚发布Red Hat Linux 9之后，该公司对其产品系列进行了一些根本性的改变。它保留了红帽商业产品的商标，特别是红帽企业Linux，并引入了Fedora Core（后来改名为Fedora），这是一个红帽赞助的，但面向社区的发行版，专为“Linux爱好者”设计。从刚开始的批评后，Linux社区接受了“新的”发行版作为Red Hat Linux的核心延续版本。 Fedora重新成为一个高质量的版本，成为市场上最受欢迎的操作系统之一。与此同时，红帽公司迅速成为全球规模最大，盈利能力最强的Linux公司，拥有创新的产品阵容，出色的客户支持以及红帽认证工程师（RHCE）认证计划等其他受欢迎的计划。 尽管Fedora的方向仍然由Red Hat，Inc.主要控制，并且该产品有时被看作是对红帽企业Linux的测试平台(小白鼠)，无论是正确的还是错误的，无可否认，Fedora是最具创新性的分发版之一。它对Linux内核，glibc和GCC的贡献是众所周知的，它最近集成了SELinux功能，虚拟化技术，系统服务管理器，先进的日志文件系统以及其他企业级功能， 。不利的一面是，Fedora仍然缺乏明确的面向桌面的策略，以使产品更容易用于“Linux爱好者”目标以外的用户。 优点：高度创新;突出的安全功能;大量支持的软件包;严格遵守自由软件的理念;具有许多流行桌面环境的Live CD的可用性缺点：Fedora的优先级倾向于倾向于企业功能，而不是桌面可用性;一些出色的边缘功能，比如早期切换到KDE 4和GNOME 3，偶尔会疏远一些桌面用户软件包管理：使用RPM软件包的YUM图形和命令行工具可用的版本：用于32位（i386）和64位（x86_64）处理器的Fedora;还有GNOME，KDE，LXDE，MATE和Xfce桌面的CD版本基于Fedora的替代方案：Korora（GNOME，KDE，LXDE桌面或Xfce桌面的Live DVD）基于红帽的备选方案：CentOS，Scientific Linux Arch LinuxArch Linux的KISS（保持简单愚蠢）哲学是在2002年由加拿大计算机科学专业毕业生Judd Vinet在2002年推出的，几年来，它一直是一个为中级和高级Linux用户设计的边缘项目。但是它“滚动更新”，只需要安装一次，然后保持一直更新，不要从头安装新的系统。这都要感谢其强大的包管理器和一个总是最新的软件库。因此，Arch Linux的“发行版”很少，而且现在只限于一个基本的安装光盘，只有在基本系统发生相当大的变化时，才会发行新的安装介质。 Arch Linux除了拥有备受推崇的“滚动发布”更新机制之外，还以其快速和强大的软件包管理器“Pacman”而闻名，能够从源代码安装软件包，并且由于其AUR基础架构，以及经过充分测试的软件包不断增加的软件库。其高度重视的文档，以及卓越的Arch Linux手册，使得一些高级Linux用户可以自行安装和定制分发。用户可以使用的强大工具意味着发行版可以无限定制到最细微的细节，并且没有两个安装可能是相同的。 不利的一面是，任何滚动更新更新机制都有其危险性：人为错误，库或依赖关系丢失，已存在于存储库中的应用程序的新版本有一个尚未报告的严重错误都可能导致系统的不稳定。在Pacman升级之后，最终导致无法启动的系统是经常遇到的。因此，Arch Linux是一种需要用户警觉并具有足够的知识来解决任何这种可能的问题的发行版。此外，偶尔安装的发行版意味着有时由于重要的系统更改或在较早的Linux内核中缺少硬件支持而无法使用旧版本。 优点：优秀的软件管理基础设施无与伦比的定制和调整选项;一流的在线文档缺点：偶尔会出现不稳定和风险软件包管理：使用TAR.XZ软件包的“Pacman”包管理器可用的版本：64位（x86_64）处理器的最小安装CD和网络安装CD映像基于Arch Linux的发行版：Manjaro Linux（与Cinnamon，Enlightenment，KDE，LXDE，MATE，Openbox，Xfce一起使用），Antergos（与GNOME 3一起使用），ArchBang Linux（使用Openbox的轻量级），Chakra GNU / Linux （使用KDE的Live CD），Bridge Linux（使用GNOME，KDE，LXDE和Xfce），Parabola GNU / Linux（免费软件），KaOS（使用KDE） PCLinuxOSPCLinuxOS于2003年由比尔·雷诺兹（Bill Reynolds）首先宣布，被称为“Texstar”。在创建自己的发行版之前，Texstar已经是Mandrake Linux社区用户的知名开发人员构建的最新的RPM包，并提供免费下载。 2003年，他决定建立一个新的发行版，最初基于Mandrake Linux，但有几个显著的可用性改进。理念是应该对初学者是友好的，具有专有内核模块，浏览器插件和媒体编解码器的开箱即用的支持，并应作为一个简单直观的图形安装程序的Live CD。 几年后的发展，PCLinuxOS正在迅速接近其预期的状态。就可用性而言，该项目为大多数Windows到Linux移民希望从他们的新操作系统中获得的许多技术提供了开箱即用的支持。在软件方面，PCLinuxOS是一个面向KDE的发行版，具有定制且始终最新版本的流行桌面环境。不断增长的软件存储库包含其他桌面，并为许多常见任务提供各种各样的桌面软件包。对于系统配置，PCLinuxOS保留了很多Mandriva优秀的控制中心，但是用APT和Synaptic（一个图形化的包管理前端）取代了它的包管理系统。 不利的一面是，PCLinuxOS缺乏任何形式的路线图或发布目标。尽管越来越多的社区参与这个项目，大多数的发展和决策仍然掌握在Texstar的手中，他们在判断发布的稳定性时倾向于保守的一面。因此，PCLinuxOS的开发过程往往是艰巨的。例如，尽管频繁要求64位版本，但开发者直到最近才开始生产64位版本。此外，该项目不提供任何安全建议，而是依靠用户通过所包括的管理工具保持系统最新的状态。 优点：对图形驱动程序，浏览器插件和媒体编解码器的开箱即用支持;滚动更新机制;最新的软件缺点：对非英语语言没有开箱即用的支持;缺乏发布计划和安全建议软件包管理：使用RPM包的高级包工具（APT）可用的版本：KDE，完整的Monty，KDE Minime，LXDE，LXDE Mini，Openbox，Openbox盆景，用于64位（x86_64）处理器体系结构的KDE GentooGentoo是Linux世界最年轻的发行版本，正因为年轻，所以能吸取在她之前的所有发行版本的优点。Gentoo最初由Daniel Robbins（FreeBSD的开发者之一）创建，首个稳定版本发布于2002年。由于开发者对FreeBSD的熟识，所以Gentoo拥有媲美FreeBSD的广受美誉的ports系统 ——Portage包管理系统。 FreeBSDFreeBSD是AT＆T UNIX通过Berkeley Software Distribution（BSD）的间接后裔，它的历史可以追溯到1993年。与Linux发行版不同，Linux发行版被定义为由Linux内核和数千个软件应用程序组成的集成软件解决方案， 而FreeBSD是一个紧密集成的操作系统，由BSD内核和所谓的“用户空间”构成（因此即使没有额外的应用程序也可以使用）。一旦安装在普通的计算机系统上，这种区别就不明显了 – 就像许多Linux发行版一样，大量易于安装的（大部分）开源应用程序也是可支持FreeBSD核心。 FreeBSD已经发展成为一个快速，高性能和非常稳定的操作系统，尤其适用于Web服务和类似的任务。许多具有关键任务计算基础设施的大型网络搜索引擎和组织已经在他们的计算机系统上部署和使用FreeBSD多年。与Linux相比，FreeBSD是在一个限制少得多的许可证下分发的，它允许为任何目的而实际上不受限制的重用和修改源代码。即使是苹果公司的Mac OS X也是从FreeBSD派生出来的。除了核心操作系统之外，该项目还提供了超过24,000个二进制和源代码形式的软件应用程序，以方便安装在FreeBSD核心上。 虽然FreeBSD当然可以用作桌面操作系统，但是它与这个部门中流行的Linux发行版并没有很好的比较。文本模式系统安装程序在硬件检测或系统配置方面提供的功能很少，在安装后的设置中将大部分配置工作留给了用户。在对现代硬件的支持方面，FreeBSD通常落后于Linux，尤其是在支持诸如无线网卡或数码相机等，高端的台式机和笔记本电脑方面。那些试图在桌面或工作站上开发项目的用户，以充分利用FreeBSD的速度和稳定性，而不是FreeBSD本身。 优点：快速稳定;安装24000多个软件应用程序（或“端口”）的可用性;非常好的文档缺点：在支持新颖和异乎寻常的硬件方面，往往落后于Linux，商业应用程序的可用性有限;缺少图形化配置工具软件包管理：使用二进制包或基于源的“端口”（TBZ）的完整命令行包管理基础架构，可用版本：用于AMD64，ARM / ARMEL，i386，IA64，MIPS / MIPSEL，PC98 PowerPC，SPARC64和Xbox处理器的安装CD基于FreeBSD的替代方案：PC-BSD（桌面），GhostBSD（带有GNOME的live DVD）其他BSD的替代品：OpenBSD，NetBSD，DragonFly BSD 下面给为选择一个Linux发行版本犯愁的朋友一些建议如果你只是需要一个桌面系统，而且既不想使用盗版，又不想花大量的钱购买商业软件，那么你就需要一款适合桌面使用的Linux发行版本了，如果你不想自己定制任何东西，不想在系统上浪费太多时间，那么很简单，你就根据自己的爱好在ubuntu、kubuntu以及xubuntu中选一款吧，三者的区别仅仅是桌面程序的不一样。如果你需要一个桌面系统，而且还想非常灵活的定制自己的Linux系统，想让自己的机器跑得更欢，不介意在Linux系统安装方面浪费一点时间，那么你的唯一选择就是Gentoo，尽情享受Gentoo带来的自由快感吧！如果你需要的是一个服务器系统，而且你已经非常厌烦各种Linux的配置，只是想要一个比较稳定的服务器系统而已，那么你最好的选择就是CentOS了，安装完成后，经过简单的配置就能提供非常稳定的服务了。如果你需要的是一个坚如磐石的非常稳定的服务器系统，那么你的唯一选择就是FreeBSD。如果你需要一个稳定的服务器系统，而且想深入摸索一下Linux的各个方面的知识，想自己定制许多内容，那么我推荐你使用Gentoo。 Linux桌面环境早期的 Linux 系统都是不带界面的，只能通过命令来管理，比如运行程序、编辑文档、删除文件等。所以，要想熟练使用 Linux，就必须记忆很多命令。 后来随着 Windows 的普及，计算机界面变得越来越漂亮，点点鼠标就能完成很多工作，人们已经习惯了图形界面化的操作，很难再忍受一片漆黑的命令行窗口了。这推动了 Linux 社区进行变革，很快推出了 Linux 系统的图形界面环境。 完成工作的方式不止一种，Linux 一直以来都以此而闻名，在图形桌面上更是如此，Linux 有各种各样的图形化桌面可供选择。 Linux 中的桌面环境也是一个程序，它和内核不是绑定的，两者的开发也不是同步的；给不带界面的 Linux 系统安装上一个桌面环境，你就能看到各种漂亮的窗口，并能用鼠标点击它们了。 上面所说各种Linux发行版其实默认附带了某种桌面环境，但如果你喜欢折腾，可以更换其他桌面环境 下面给大家介绍几款比较流行的桌面环境： KDEKDE 是 K Desktop Environment 的缩写，中文译为“K桌面环境”。 KDE 是基于大名鼎鼎的 Qt 的，最初于 1996 年作为开源项目公布，并在 1998 年发布了第一个版本，现在 KDE 几乎是排名第一的桌面环境了。 许多流行的 Linux 发行版都提供了 KDE 桌面环境，比如 Ubuntu、Linux Mint、OpenSUSE、Fedora、Kubuntu、PC Linux OS 等。 KDE 和 Windows 比较类似，各位初学者相信都是 Windows 的用户，所以切换到 KDE 也不会有太大的障碍。 KDE 允许你把应用程序图标和文件图标放置在桌面的特定位置上。单击应用程序图标，Linux 系统就会运行该应用程序。单击文件图标，KDE 桌面就会确定使用哪种应用程序来处理该文件。 KDE 是所有桌面环境中最容易定制的。在其他桌面环境中，你需要几个插件、窗口组件和调整工具才可以定制环境，KDE 将所有工具和窗口组件都塞入到系统设置中。借助先进的设置管理器，可以控制一切，不需要任何第三方工具，就可以根据用户的喜好和要求来美化及调整桌面。 KDE 项目组还还发了大量的可运行在 KDE 环境中的应用程序，包括 Dolphin（文件管理工具）、Konsole（终端）、Kate（文本编辑工具）、Gwenview（图片查看工具）、Okular（文档及PDF查看工具）、Digikam（照片编辑和整理工具）、KMail（电子邮件客户软件）、Quassel（IRC客户软件）、K3b（DVD刻录程序）、Krunner（启动器）等，它们都是默认安装的。 对 KDE 优缺点的总结：优点：KDE 几乎是最先进最强大的桌面环境，它外观优美、高度可定制、兼容比较旧的硬件设备缺点：Kmail 等一些组件的配置对新手来说过于复杂。 GNOMEGNOME 是 the GNU Network Object Model Environment 的缩写，中文译为“GNU网络对象模型环境”。 GNOME 于 1999 年首次发布，现已成为许多Linux发行版默认的桌面环境（不过用得最多的是 Red Hat Linux）。 GNOME 的特点是简洁、运行速度快，但是没有太多的定制选项，用户需要安装第三方工具来实现。 GNOME 甚至不包括一些简单的调整选项，比如更改主题、更改字体等，就这两种基本的调整而言，用户都需要安装第三方工具。所以，GONME 适合那些不需要高度定制界面的用户。 GNOME 被用作 Fedora 中的默认桌面环境，提供在几款流行的 Linux 发行版中，比如 Ubuntu、Debian、OpenSUSE 等。 2011 年，GNOME 3 进行了重大更新，不再采用传统的 Windows 风格的界面，而是进行了全新的设计，惊艳了很多用户。GNOME 3 的这种行为也导致部分用户和开发人员不满，他们又开发了多款其他的桌面环境，比如 MATE 和 Cinnamon。 对 GNOME 优缺点的总结：优点：简单易用，可通过插件来扩展功能。缺点：对插件的管理能力比较差，也缺少其它桌面环境拥有的许多功能。 UnityUnity 是由 Ubuntu 的母公司 Canonical 开发的一款外壳。之所以说它是外壳，是因为 Unity 运行在 GNOME 桌面环境之上，使用了所有 GNOME 的核心应用程序。 2010 年，Unity 第一个版本发布，此后经过数次改进，如今和其它的桌面环境一样，也可以安装到其它的 Linux 发行版上了。 Unity 使用了不同的界面风格，如果你用的是 Ubuntu Linux 发行版，你会注意到 Unity 与 KDE 和 GNOME 桌面环境有些不一样。 Unity 在左边有一个启动器，位于启动器顶部的是搜索图标，又叫“Dash”。在 Dash 上搜索文件时，不仅会给出来自硬盘的搜索结果，还会给出来自在线来源的搜索结果，比如 Google Drive、Facebook、Picasa、Flick 及其他。 Unity 还提供了隐藏启动器、触摸侧边栏就显示的选项，用户还可以调高/调低显示启动器菜单的灵敏度。 Unity 很简单、运行速度快，但 Unity 在系统设置下却没有定制桌面的太多选项，要想安装主题或者定制另外不同的选项，比如系统菜单是否应该总是可见，或者“从启动器图标一次点击最小化”，用户需要安装第三方工具。CCSM 和 Unity Tweak Tool 是面向 Unity 桌面环境的非常流行的定制工具。对 Unity 优缺点的总结：优点：界面简洁直观，可以通过第三方工具来深度定制，而且使用了平视显示器（HUD）等新技术。缺点：默认的定制功能比较差劲，通知机制一般。 MATE上面我们提到，GNOME 3 进行了全新的界面设计，这招致一些用户的不满，他们推出了其它的桌面环境，MATE 就是其中之一。 MATE 是一种从现在无人维护的 GNOME 2 代码库派生出来的桌面环境。 MATE 让人觉得在使用旧的桌面环境，但是结合了历年来界面方面的诸多改进。MATE 还非常适用于低配计算机，所以如果你有一台旧的或速度较慢的计算机，可以使用 MATE。 MATE 还是许多流行的 Linux 发行版随带的，比如 Ubuntu、Linux Mint、Mageia、Debian 及另外更多发行版。Ubuntu MATE 头一回是官方版本。 “欢迎首次发布的 Ubuntu MATE 官方版本。现在，用户将更容易更新软件，因为所有组件现在都在 Ubuntu 软件库中。” MATE 自带的应用程序包括 Caja（文件管理工具）、Pluma（文本编辑工具）、Atril（文档查看工具）、Eye of MATE（图像查看工具）等，如果用户不需要其他功能完备的桌面环境的所有额外功能，那么 MATE 对他们来说是一款简单的轻量级桌面环境。 对 META 优缺点的总结：优点：轻量级的桌面环境，能够兼容教旧的硬件设备。缺点：暂无 Cinnamon与 MATE 类似，Cinnamon 是由 Linux Mint 团队因为不满 Gnome 3 的改进而开发的另一种桌面环境。但 Cinnamon 与 MATE 不同之处在于，Cinnamon 建立在 Gnome 3 的基础上。Cinnamon 是新的，而且在积极开发之中，但这款出色的桌面环境没有因新颖而在功能方面有所减弱。 Cinnamon 拥有 GNOME 和 Unity 等其它桌面环境所没有的种种功能。Cinnamon 是高度可定制的桌面环境，不需要任何外部插件、窗口组件和调整工具来定制桌面。Cinnamon 甚至可以通过设置管理器本身来下载并安装主题，甚至不需要打开互联网浏览器。 由于种种出色的所需功能，Cinnamon 对任何刚接触 Linux 的新用户来说都非常方便。许多用户放弃使用 Linux，是因为他们并不了解 Linux 的工作方式，但是我强烈建议新手应从 Cinnamon 桌面环境开始入手。 许多流行的 Linux 发行版提供了各自版本的 Cinnamon，比如 Ubuntu、Fedora、OpenSUSE、Gentoo、Arch Linux 等。Cinnamon 还是 Linux Mint 的默认桌面环境。 对 Cinnamon 优缺点的总结：优点：成熟完美，高度可性质，适合 Linux 新手。缺点：有时候可能会有软件错误]]></content>
      <categories>
        <category>大数据</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下mysql的卸载和安装使用]]></title>
    <url>%2F2019%2F07%2F30%2FLearn%2Fwindows%E4%B8%8Bmysql%E7%9A%84%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[mysql的卸载停止服务，卸载右键开始菜单，打开powershell(管理员)，cd到windows版mysql的解压路径 1234567891011121314151617181920212223PS C:\Windows\system32&gt; cd D:\ZTGX\github\mysql-8.0.16-winx64PS D:\ZTGX\github\mysql-8.0.16-winx64&gt; ls 目录: D:\ZTGX\github\mysql-8.0.16-winx64Mode LastWriteTime Length Name---- ------------- ------ ----da---- 2019/4/13 22:39 bind----- 2019/7/29 19:42 datada---- 2019/4/13 22:31 docsda---- 2019/4/13 22:31 etcda---- 2019/4/13 22:31 includeda---- 2019/4/13 22:39 libda---- 2019/4/13 22:31 runda---- 2019/4/13 22:31 shareda---- 2019/4/13 22:31 var-a---- 2019/4/13 19:46 335809 LICENSE-a---- 2019/4/13 19:46 101807 LICENSE.router-a---- 2019/7/21 13:14 715 my.ini-a---- 2019/4/13 19:46 687 README-a---- 2019/4/13 19:46 700 README.router 执行服务停止命令 123PS D:\ZTGX\github\mysql-8.0.16-winx64&gt; net stop mysqlMySQL 服务正在停止..MySQL 服务已成功停止。 卸载mysql 12PS D:\ZTGX\github\mysql-8.0.16-winx64&gt; mysqld removeService successfully removed. 打开注册表，删除mysql相关目录win+r打开运行，输入regedit，进入注册表编辑器，删除以下文件 HKEY_LOCAL_MACHINE\SYSTEM\ControlSet001\Services\EventLog\Application\MySQLD Service mysql的安装下载mysql压缩包https://dev.mysql.com/downloads/mysql/ 配置环境变量12345NAME: MYSQL_HOMEVALUE: D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64NAME: pathVALUE: %MYSQL_HOME%\bin 新建my.ini文件,data文件夹路径：D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64 my.ini文件： 12345678910111213141516171819202122232425262728[mysqld]# 设置mysql的安装目录basedir=D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64# 设置mysql数据库的数据的存放目录datadir=D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64/data# 设置默认使用的端口port=3306# 允许最大连接数max_connections=200# 允许连接失败的次数。这是为了防止有人试图攻击数据库max_connect_errors=10# 服务端使用的字符集character-set-server=utf8mb4# 数据库字符集对应一些排序等规则使用的字符集collation-server=utf8mb4_general_ci# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用“mysql_native_password”插件作为认证加密方式# MySQL8.0默认认证加密方式为caching_sha2_passworddefault_authentication_plugin=mysql_native_password[mysql]# 设置mysql客户端默认字符集default-character-set=utf8mb4[client]default-character-set=utf8mb4port=3306 以管理员身份运行命令提示符12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061PS C:\Windows\system32&gt; cd D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64#初始化MySQL数据库PS D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64&gt; mysqld --initialize --console2019-07-30T10:50:30.522984Z 0 [System] [MY-013169] [Server] D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64\bin\mysqld.exe (mysqld 8.0.16) initializing of server in progress as process 209522019-07-30T10:50:54.333588Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: u3qnRFr&gt;(M#a2019-07-30T10:51:03.275327Z 0 [System] [MY-013170] [Server] D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64\bin\mysqld.exe (mysqld 8.0.16) initializing of server has completed#安装MySQL服务PS D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64&gt; mysqld installService successfully installed.#启动MySQL服务PS D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64&gt; net start mysqlMySQL 服务正在启动 ..MySQL 服务已经启动成功。#使用临时密码登录【初始化mysql时产生】PS D:\develop_installation_package\win-mysql-8.0\mysql-8.0.16-winx64&gt; mysql -uroot -pEnter password: ************Welcome to the MySQL monitor. Commands end with ; or \g.#修改mysql登录密码mysql&gt; alter user 'root'@'localhost' identified by '123456';Query OK, 0 rows affected (0.52 sec)#设置mysql远程登录mysql&gt; use mysqlDatabase changedmysql&gt; select host, user, authentication_string, plugin from user;+-----------+------------------+------------------------------------------------------------------------+-----------------------+| host | user | authentication_string | plugin |+-----------+------------------+------------------------------------------------------------------------+-----------------------+| localhost | mysql.infoschema | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || localhost | mysql.session | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || localhost | mysql.sys | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || localhost | root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | mysql_native_password |+-----------+------------------+------------------------------------------------------------------------+-----------------------+4 rows in set (0.00 sec)mysql&gt; create user 'root'@'%' identified by '123456';Query OK, 0 rows affected (0.62 sec)mysql&gt; select host, user, authentication_string, plugin from user;+-----------+------------------+------------------------------------------------------------------------+-----------------------+| host | user | authentication_string | plugin |+-----------+------------------+------------------------------------------------------------------------+-----------------------+| % | root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | mysql_native_password || localhost | mysql.infoschema | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || localhost | mysql.session | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || localhost | mysql.sys | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || localhost | root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | mysql_native_password |+-----------+------------------+------------------------------------------------------------------------+-----------------------+5 rows in set (0.00 sec)mysql&gt; GRANT ALL ON *.* TO 'root'@'%';Query OK, 0 rows affected (0.47 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.13 sec) 说明：mysql 8.0之后，创建用户和赋予权限是分开的，所以需要分开操作。不能再像5.7一样，一条命令创建+赋予远程登录权限]]></content>
      <categories>
        <category>实战教程</category>
      </categories>
      <tags>
        <tag>实战教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solo使用教程]]></title>
    <url>%2F2019%2F07%2F30%2FLearn%2Fsolo%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[注：需要在windows下安装mysql，具体步骤：http://www.zzditto.cn/2019/07/30/windows%E4%B8%8Bmysql%E7%9A%84%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/#more 登录mysql，创建solo数据库12mysql&gt; create database solo;Query OK, 1 row affected (0.64 sec) 下载solo安装包https://github.com/b3log/solo/releases?utm_source=hacpai.com 下载 solo-v3.6.3.war 解压，进入解压目录执行解压目录下，shift+鼠标右键，选择powershell窗口 1234567PS D:\develop_installation_package\solo\solo-v3.6.3&gt; java -cp "WEB-INF/lib/*;WEB-INF/classes" org.b3log.solo.Starter[INFO ]-[2019-07-30 20:42:23]-[org.b3log.solo.util.Markdowns:135]: [markdown-http] is not available, uses built-in [flexmark] for markdown processing. Please read FAQ section in user guide (https://hacpai.com/article/1492881378588) for more details.[INFO ]-[2019-07-30 20:42:23]-[org.b3log.solo.SoloServletListener:99]: Solo is booting [ver=3.6.3, servletContainer=jetty/9.4.12.v20180830, os=Windows 10, isDocker=false, markdownHttpAvailable=false, pid=7640, runtimeDatabase=MYSQL, runtimeMode=PRODUCTION, jdbc.username=root, jdbc.URL=jdbc:mysql://localhost:3306/solo?useUnicode=yes&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=UTC][INFO ]-[2019-07-30 20:42:23]-[com.zaxxer.hikari.HikariDataSource:110]: HikariPool-1 - Starting...[INFO ]-[2019-07-30 20:42:23]-[com.zaxxer.hikari.HikariDataSource:123]: HikariPool-1 - Start completed.[INFO ]-[2019-07-30 20:42:23]-[org.b3log.solo.service.InitService:191]: It's your first time setup Solo, initialize tables in database [MYSQL][WARN ]-[2019-07-30 20:42:28]-[org.b3log.solo.service.InitService:161]: Solo has not been initialized, please open your browser to init Solo 访问web页面localhost:8080 需要注册github账号，注册地址：https://github.com/join?source=header-home点击：开始使用，输入github账号即可使用]]></content>
      <categories>
        <category>实战教程</category>
      </categories>
      <tags>
        <tag>实战教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo使用教程]]></title>
    <url>%2F2019%2F07%2F30%2FLearn%2Fhexo%E7%9A%84%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[windows环境 安装node.jshttps://nodejs.org/en/ 安装githttps://git-scm.com/download/win 使用管理员权限操作命令行开始菜单点击鼠标右键，选择powershell(管理员) 执行命令安装hexo1234567PS C:\Windows\system32&gt; npm install -g hexo-cliC:\Users\LWZ22\AppData\Roaming\npm\hexo -&gt; C:\Users\LWZ22\AppData\Roaming\npm\node_modules\hexo-cli\bin\hexonpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.9 (node_modules\hexo-cli\node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.9: wanted &#123;"os":"darwin","arch":"any"&#125; (current: &#123;"os":"win32","arch":"x64"&#125;)+ hexo-cli@2.0.0added 187 packages from 432 contributors in 108.919s 初始化hexo。路径为自定义路径【这里是在D盘下新建blog文件夹】 123456789101112131415161718192021222324PS C:\Windows\system32&gt; hexo init D:\blogINFO Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitCloning into 'D:\blog'...remote: Enumerating objects: 9, done.remote: Counting objects: 100% (9/9), done.remote: Compressing objects: 100% (7/7), done.remote: Total 77 (delta 4), reused 5 (delta 2), pack-reused 68Unpacking objects: 100% (77/77), done.Submodule 'themes/landscape' (https://github.com/hexojs/hexo-theme-landscape.git) registered for path 'themes/landscape'Cloning into 'D:/blog/themes/landscape'...remote: Enumerating objects: 43, done.remote: Counting objects: 100% (43/43), done.remote: Compressing objects: 100% (34/34), done.remote: Total 956 (delta 19), reused 19 (delta 8), pack-reused 913Receiving objects: 100% (956/956), 3.16 MiB | 30.00 KiB/s, done.Resolving deltas: 100% (509/509), done.Submodule path 'themes/landscape': checked out '73a23c51f8487cfcd7c6deec96ccc7543960d350'[32mINFO [39m Install dependencies系统找不到指定的路径。Error: JAVA_HOME is incorrectly set. Please update D:\install\hadoop-2.7.6.tar\hadoop-2.7.6\conf\hadoop-env.cmd'-Dhadoop.log.dir' 不是内部或外部命令，也不是可运行的程序或批处理文件。INFO Start blogging with Hexo! cd到博客目录，执行安装程序 123456789PS C:\Windows\system32&gt; cd D:\blogPS D:\blog&gt; npm installnpm WARN deprecated core-js@1.2.7: core-js@&lt;2.6.8 is no longer maintained. Please, upgrade to core-js@3 or at least to actual version of core-js@2.npm notice created a lockfile as package-lock.json. You should commit this file.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.9 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.9: wanted &#123;"os":"darwin","arch":"any"&#125; (current: &#123;"os":"win32","arch":"x64"&#125;)added 340 packages from 500 contributors and audited 6879 packages in 68.479sfound 0 vulnerabilities 安装完成，打开web页面hexo s 或 hexo server 123PS D:\blog&gt; hexo serverINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 浏览器访问 localhost:4000 将hexo部署到github 点击 git Bash 【需要上传的命令都需要git bash，使用cmd.exe会报错】点击github页面，新建仓库。仓库名为 用户名.github.io。然后复制仓库总网址 在blog目录下安装git插件123456789LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ npm install --save hexo-deployer-gitnpm WARN babel-eslint@10.0.2 requires a peer of eslint@&gt;= 4.12.1 but none is installed. You must install peer dependencies yourself.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.9 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.9: wanted &#123;"os":"darwin","arch":"any"&#125; (current: &#123;"os":"win32","arch":"x64"&#125;)+ hexo-deployer-git@1.0.0added 24 packages from 10 contributors and audited 9166 packages in 21.011sfound 0 vulnerabilities 编辑blog的_config.yml文件【设置type为git，添加repo和branch】123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/zzditto/zzditto.github.io.git branch: master 在git bash中设置github的邮箱和用户名如果不输入，直接hexo d上传，报错 12345*** Please tell me who you are.Run git config --global user.email "you@example.com" git config --global user.name "Your Name" 在命令行输入： 12345LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ git config --global user.email "18332779639@163.com"LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ git config --global user.name "zzditto" 上传命令： hexo d 然后会提示输入github的用户名和密码，登录，稍等片刻，上传成功 使用github访问https://zzditto.github.io/ 创建第一篇博客在blog即博客安装的总目录下，鼠标右键，打开git bash窗口 创建md文件123LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ hexo new '第一篇博客'INFO Created: D:\blog\source\_posts\第一篇博客.md 在md文件中添加内容打开win下的博客目录，使用makedown编辑器打开此文件，添加内容，ctrl+s保存 清除原来缓存1234LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ hexo cleanINFO Deleted database.INFO Deleted public folder. 重新生成html页面文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ hexo gINFO Start processingINFO Files loaded in 659 msINFO Generated: index.htmlINFO Generated: tags/index.htmlINFO Generated: about/index.htmlINFO Generated: schedule/index.htmlINFO Generated: categories/index.htmlINFO Generated: CNAMEINFO Generated: archives/index.htmlINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/avatar.gifINFO Generated: images/algolia_logo.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/cc-by-nc.svgINFO Generated: images/cc-by-sa.svgINFO Generated: images/cc-by.svgINFO Generated: images/apple-touch-icon-next.pngINFO Generated: images/cc-zero.svgINFO Generated: images/logo.svgINFO Generated: images/quote-l.svgINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/quote-r.svgINFO Generated: images/favicon-32x32-next.pngINFO Generated: archives/2019/07/index.htmlINFO Generated: categories/大数据/linux/index.htmlINFO Generated: categories/实战教程/index.htmlINFO Generated: tags/Linux/index.htmlINFO Generated: tags/Ambari/index.htmlINFO Generated: tags/实战教程/index.htmlINFO Generated: tags/HDP/index.htmlINFO Generated: archives/2019/index.htmlINFO Generated: categories/大数据/index.htmlINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: js/algolia-search.jsINFO Generated: css/main.cssINFO Generated: js/affix.jsINFO Generated: js/exturl.jsINFO Generated: js/js.cookie.jsINFO Generated: js/post-details.jsINFO Generated: js/next-boot.jsINFO Generated: js/scroll-cookie.jsINFO Generated: js/scrollspy.jsINFO Generated: lib/font-awesome/bower.jsonINFO Generated: js/motion.jsINFO Generated: live2dw/lib/L2Dwidget.min.jsINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: js/utils.jsINFO Generated: live2dw/lib/L2Dwidget.min.js.mapINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: lib/velocity/velocity.min.jsINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: 2019/07/30/第一篇博客/index.htmlINFO Generated: 2019/07/23/hello-world/index.htmlINFO Generated: 2019/07/24/test-md/index.htmlINFO Generated: live2dw/lib/L2Dwidget.0.min.jsINFO Generated: js/schemes/pisces.jsINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: 2019/07/30/hexo使用教程/index.htmlINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: js/schemes/muse.jsINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: 2019/07/24/Ambari离线安装/index.htmlINFO Generated: live2dw/lib/L2Dwidget.0.min.js.mapINFO Generated: lib/jquery/index.jsINFO Generated: lib/velocity/velocity.jsINFO 66 files generated in 1.46 sINFO Congratulations! Your are using the latest version of theme NexT. 启动12345LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.INFO Congratulations! Your are using the latest version of theme NexT. 同步至github123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108LWZ@DESKTOP-AB2NRQ5 MINGW64 /d/blog$ hexo dINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...warning: LF will be replaced by CRLF in 2019/07/23/hello-world/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in 2019/07/24/Ambari离线安装/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in 2019/07/24/test-md/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in about/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in archives/2019/07/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in archives/2019/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in archives/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in categories/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in categories/大数据/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in css/main.css.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/affix.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/algolia-search.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/exturl.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/js.cookie.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/motion.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/next-boot.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/post-details.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/schemes/muse.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/schemes/pisces.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/scroll-cookie.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/scrollspy.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in js/utils.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/font-awesome/css/font-awesome.css.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/font-awesome/css/font-awesome.min.css.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/jquery/index.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/velocity/velocity.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/velocity/velocity.min.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/velocity/velocity.ui.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in lib/velocity/velocity.ui.min.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in live2dw/lib/L2Dwidget.0.min.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in live2dw/lib/L2Dwidget.min.js.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in schedule/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in tags/Ambari/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in tags/HDP/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in tags/Linux/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in tags/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in 2019/07/30/hexo使用教程/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in 2019/07/30/第一篇博客/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in categories/大数据/linux/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in categories/实战教程/index.html.The file will have its original line endings in your working directorywarning: LF will be replaced by CRLF in tags/实战教程/index.html.The file will have its original line endings in your working directory[master 4c2c499] Site updated: 2019-07-30 13:19:35 21 files changed, 6538 insertions(+), 88 deletions(-) create mode 100644 "2019/07/30/hexo\344\275\277\347\224\250\346\225\231\347\250\213/index.html" create mode 100644 "2019/07/30/\347\254\254\344\270\200\347\257\207\345\215\232\345\256\242/index.html" create mode 100644 "categories/\345\244\247\346\225\260\346\215\256/linux/index.html" create mode 100644 "categories/\345\256\236\346\210\230\346\225\231\347\250\213/index.html" create mode 100644 "tags/\345\256\236\346\210\230\346\225\231\347\250\213/index.html"Enumerating objects: 84, done.Counting objects: 100% (84/84), done.Delta compression using up to 12 threadsCompressing objects: 100% (31/31), done.Writing objects: 100% (48/48), 10.89 KiB | 857.00 KiB/s, done.Total 48 (delta 21), reused 0 (delta 0)remote: Resolving deltas: 100% (21/21), completed with 15 local objects.To https://github.com/zzditto/zzditto.github.io.git d462eae..4c2c499 HEAD -&gt; masterBranch 'master' set up to track remote branch 'master' from 'https://github.com/zzditto/zzditto.github.io.git'.INFO Deploy done: git 访问本机：localhost:4000 网络:http://zzditto.github.io 绑定域名后:http://www.zzditto.cn/]]></content>
      <categories>
        <category>实战教程</category>
      </categories>
      <tags>
        <tag>实战教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDP离线安装]]></title>
    <url>%2F2019%2F07%2F24%2FBigData%2FHDP%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[注意在实际生产环境下，需要离线安装，但是一般都是自定义yum源，将所需的rpm软件包及其依赖提前准备好并制作一个yum源服务器，供集群的各节点使用。本文采用的方法很笨，具体yum源的制作请看http://www.zzditto.cn/2019/08/19/HDP%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E5%88%B6%E4%BD%9C%E6%9C%AC%E5%9C%B0yum%E6%BA%90/,下文对软件的安装在yum源制作完成之后，都可使用yum -y install packagename 安装。 1.检查系统版本HDP2.6需要centos7版本注：系统需要linux的虚拟化主机版或者桌面版。最小化安装缺乏mysql安装的部分依赖包 cat /etc/redhat-release 适用于Redhat系linux12[root@localhost ~]# cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 2.检查分区硬盘大小123456789[root@localhost ~]# df -THFilesystem Type Size Used Avail Use% Mounted on/dev/mapper/centos-root xfs 19G 11G 7.8G 58% /devtmpfs devtmpfs 3.1G 0 3.1G 0% /devtmpfs tmpfs 3.1G 0 3.1G 0% /dev/shmtmpfs tmpfs 3.1G 13M 3.1G 1% /runtmpfs tmpfs 3.1G 0 3.1G 0% /sys/fs/cgroup/dev/sda1 xfs 1.1G 153M 911M 15% /boottmpfs tmpfs 607M 0 607M 0% /run/user/0 系统要求：【需在装载系统时分好】root：100Gswap：同内存大小home：40G数据盘：剩余容量 3.准备离线资源包JDKhttps://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html ntphttpdyummysqlmysql-connectmariadbpostgresqlAmbarihttps://docs.hortonworks.com/HDPDocuments/Ambari-2.6.2.2/bk_ambari-installation/content/ambari_repositories.html HDPhttps://docs.hortonworks.com/HDPDocuments/Ambari-2.6.2.2/bk_ambari-installation/content/hdp_26_repositories.html 1234567891011[root@vm01 apps]# lltotal 0drwxr-xr-x. 2 root root 100 Aug 15 10:08 httpddrwxr-xr-x. 2 root root 40 Aug 15 10:07 jdkdrwxr-xr-x. 2 root root 54 Aug 15 10:08 mysqldrwxr-xr-x. 2 root root 48 Aug 15 10:09 mysql-connectdrwxr-xr-x. 2 root root 143 Aug 15 10:09 ntpdrwxr-xr-x. 2 root root 150 Aug 15 10:12 postgresqldrwxr-xr-x. 2 root root 183 Aug 15 10:13 yum[root@vm01 apps]# pwd/opt/apps HDP和Ambari体积较大，可提前上传 4.新机器要干的事情设置ip【all】12345678910111213141516171819[root@localhost ~]# cd /etc/sysconfig/network-scripts/[root@localhost network-scripts]# vi ifcfg-ens33TYPE=EthernetBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33DEVICE=ens33ONBOOT=yesIPADDR=192.168.133.3NETMASK=255.255.255.0GATEWAY=192.168.133.2DNS1=8.8.8.8DNS2=114.114.114.114 集群中每个节点需不同设置，不同之处在于IPADDR。设置完之后重启网络服务 1[root@localhost network-scripts]# systemctl restart network 查看本机ip是否更改成功，并尝试ping其他节点和外网123456789101112131415161718192021222324[root@localhost network-scripts]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:6f:d4:70 brd ff:ff:ff:ff:ff:ff inet 192.168.133.3/24 brd 192.168.133.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::1a15:8411:8d59:624e/64 scope link noprefixroute valid_lft forever preferred_lft forever[root@localhost network-scripts]# ping 192.168.133.4PING 192.168.133.4 (192.168.133.4) 56(84) bytes of data.64 bytes from 192.168.133.4: icmp_seq=1 ttl=64 time=0.349 ms64 bytes from 192.168.133.4: icmp_seq=2 ttl=64 time=0.232 ms^C--- 192.168.133.4 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.232/0.290/0.349/0.060 ms[root@localhost network-scripts]# ping www.baidu.comping: www.baidu.com: Name or service not known离线安装，无法ping通外网 修改主机名【all】12[root@localhost network-scripts]# vi /etc/hostnamevm01 每个节点分别修改，修改需要重启生效！！！ 修改/etc/sysconfig/network【all】123[root@vm01 ~]# vi /etc/sysconfig/network# Created by anacondaNETWORKING=yes 每个节点分别修改 关闭防火墙【all】关闭防火墙，设置开机不自启。每个节点分别设置 1234567[root@vm01 jdk]# systemctl stop firewalld[root@vm01 jdk]# systemctl disable firewalld[root@vm01 jdk]# systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) 修改主机映射【all】123456[root@vm01 ~]# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.133.3 vm01192.168.133.4 vm02192.168.133.5 vm03 发送到每个节点 123456[root@vm01 apps]# for i in &#123;2,3&#125;;&gt; do&gt; scp /etc/hosts vm0$i:/etc/&gt; done;hosts 100% 221 183.4KB/s 00:00hosts 100% 221 122.0KB/s 00:00 ssh免密登录【master】注意：发送公匙时，主节点也需要发送 123456789101112131415161718192021[root@vm01 ~]# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:N/7YjYkiwm7xGSUtkb/qRagW1X7GWoc8O7STCBz3eKU root@vm01The key's randomart image is:+---[RSA 2048]----+| . || o. || o+o . || oo=+= + || . ++S.E . || .o.o.@ B || .oo ++ B || .+ =.. B + || o.o.. .o = . |+----[SHA256]-----+ 12345678910[root@vm01 ~]# ssh-copy-id vm01/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@vm01's password:Number of key(s) added: 1Now try logging into the machine, with: "ssh 'vm01'"and check to make sure that only the key(s) you wanted were added. 12345678910[root@vm01 ~]# ssh-copy-id vm02/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@vm02's password:Number of key(s) added: 1Now try logging into the machine, with: "ssh 'vm02'"and check to make sure that only the key(s) you wanted were added. 12345678910[root@vm01 ~]# ssh-copy-id vm03/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@vm03's password:Number of key(s) added: 1Now try logging into the machine, with: "ssh 'vm03'"and check to make sure that only the key(s) you wanted were added. 测试免密登录是否成功： 1234[root@vm01 ~]# ssh vm01 date;ssh vm02 date;ssh vm03 date;Wed Jul 24 14:07:28 CST 2019Wed Jul 24 14:07:28 CST 2019Wed Jul 24 13:26:38 CST 2019 如果发现ssh连接其他机器较慢解决： 123456789101112131415[root@vm01 apps]# vi /etc/ssh/sshd_config#PermitUserEnvironment no#Compression delayed#ClientAliveInterval 0#ClientAliveCountMax 3#ShowPatchLevel noUseDNS no#PidFile /var/run/sshd.pid#MaxStartups 10:30:100#PermitTunnel no#ChrootDirectory none[root@vm01 apps]# systemctl restart sshd 修改ssh设置里的usedns为no，此值被注释，默认是yes参考：https://blog.csdn.net/kanghaha/article/details/51986771 重启网络服务【all】 1[root@localhost network-scripts]# systemctl restart network 安装jdk【all】上传，解压 123456[root@vm01 jdk]# pwd/opt/apps/jdk[root@vm01 jdk]# lltotal 181168drwxr-xr-x. 8 10 143 255 Jul 22 2017 jdk1.8.0_144-rw-r--r--. 1 root root 185515842 Jul 24 11:33 jdk-8u144-linux-x64.tar.gz 分发jdk包 12345# &#123;2,5&#125;代表循环到2和5，不是2~5[root@vm01 apps]# for i in &#123;2,3&#125;&gt; do&gt; scp -r ./jdk/jdk1.8.0_144/ vm0$i:/opt/apps/jdk/&gt; done; 配置环境变量 123[root@vm01 jdk1.8.0_144]# vi /etc/profileexport JAVA_HOME=/opt/apps/jdk/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin 更新，并分发 123456789[root@vm01 apps]# source /etc/profile[root@vm01 apps]# jps3543 Jps[root@vm01 apps]# for i in &#123;2,3&#125;&gt; do&gt; scp /etc/profile vm0$i:/etc/&gt; done;profile 100% 1898 1.5MB/s 00:00profile 100% 1898 1.0MB/s 00:00 其余节点，同更新检查是否配置成功 12[root@vm01 jdk1.8.0_144]# jps20110 Jps 修改文件限制【all】1234567891011121314[root@vm01 jdk]# vi /etc/security/limits.conf#在conf文件末尾添加#End of file* soft nofile 65536* hard nofile 65536* soft nproc 131072* hard nproc 131072[root@vm01 apps]# for i in &#123;2,3&#125;&gt; do&gt; scp /etc/security/limits.conf vm0$i:/etc/security/&gt; done;limits.conf 100% 2502 2.0MB/s 00:00limits.conf 100% 2502 1.8MB/s 00:00 关闭selinux【all】设置并分发 12345678910111213141516171819[root@vm01 jdk1.8.0_144]# vi /etc/selinux/config# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of three values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected.# mls - Multi Level Security protection.SELINUXTYPE=targeted[root@vm01 apps]# for i in &#123;2,3&#125;&gt; do&gt; scp /etc/selinux/config vm0$i:/etc/selinux/&gt; done;config 100% 546 907.1KB/s 00:00config 100% 546 732.2KB/s 00:00 同步时钟【all】上传ntp的rpm包，安装。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@vm03 ntp]# lltotal 2428-rw-r--r--. 1 root root 67624 Aug 16 18:15 autogen-libopts-5.18-5.el7.x86_64.rpm-rw-r--r--. 1 root root 562052 Aug 16 18:15 ntp-4.2.6p5-28.el7.centos.x86_64.rpm-rw-r--r--. 1 root root 88004 Aug 16 18:15 ntpdate-4.2.6p5-28.el7.centos.x86_64.rpm-rw-r--r-- 1 root root 504632 Aug 16 18:14 openssl-1.0.2k-16.el7_6.1.x86_64.rpm-rw-r--r-- 1 root root 1251908 Aug 16 18:14 openssl-libs-1.0.2k-16.el7_6.1.x86_64.rpm[root@vm01 apps]# for i in &#123;2,3&#125;&gt; do&gt; scp -r /opt/apps/ntp/ vm0$i:/opt/apps/&gt; done;#报错，这是需要升级。卸载旧的，安装新的即可[root@vm03 ntp]# rpm -ivh openssl-libs-1.0.2k-16.el7_6.1.x86_64.rpmwarning: openssl-libs-1.0.2k-16.el7_6.1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%] file /usr/lib64/.libcrypto.so.10.hmac from install of openssl-libs-1:1.0.2k-16.el7_6.1.x86_64 conflicts with file from package openssl-libs-1:1.0.1e-60.el7.x86_64[root@vm03 ntp]# rpm -e --nodeps openssl-libs-1:1.0.1e-60.el7.x86_64[root@vm03 ntp]# rpm -ivh openssl-libs-1.0.2k-16.el7_6.1.x86_64.rpmwarning: openssl-libs-1.0.2k-16.el7_6.1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:openssl-libs-1:1.0.2k-16.el7_6.1 ################################# [100%][root@vm03 ntp]# rpm -e --nodeps openssl-1:1.0.1e-60.el7.x86_64[root@vm03 ntp]# rpm -ivh openssl-1.0.2k-16.el7_6.1.x86_64.rpmwarning: openssl-1.0.2k-16.el7_6.1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:openssl-1:1.0.2k-16.el7_6.1 ################################# [100%][root@vm03 ntp]# rpm -e --nodeps ntpdate-4.2.6p5-25.el7.centos.x86_64[root@vm03 ntp]# rpm -ivh ntpdate-4.2.6p5-28.el7.centos.x86_64.rpmwarning: ntpdate-4.2.6p5-28.el7.centos.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:ntpdate-4.2.6p5-28.el7.centos ################################# [100%][root@vm03 ntp]# rpm -ivh autogen-libopts-5.18-5.el7.x86_64.rpmwarning: autogen-libopts-5.18-5.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%] package autogen-libopts-5.18-5.el7.x86_64 is already installed[root@vm03 ntp]# rpm -ivh ntp-4.2.6p5-28.el7.centos.x86_64.rpmwarning: ntp-4.2.6p5-28.el7.centos.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:ntp-4.2.6p5-28.el7.centos ################################# [100%]成都 安装时，需按照依赖性顺序安装，否则会报错安装好后，启动，设置开机自启。分节点安装设置 123456789101112131415161718192021[root@vm01 ntp]# systemctl start ntpd[root@vm01 ntp]# systemctl enable ntpdCreated symlink from /etc/systemd/system/multi-user.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.[root@vm01 ntp]# systemctl status ntpd● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2019-07-24 11:58:03 CST; 12s ago Main PID: 20257 (ntpd) CGroup: /system.slice/ntpd.service └─20257 /usr/sbin/ntpd -u ntp:ntp -gJul 24 11:58:03 vm01 ntpd[20257]: proto: precision = 0.028 usecJul 24 11:58:03 vm01 ntpd[20257]: 0.0.0.0 c01d 0d kern kernel time sync enabledJul 24 11:58:03 vm01 ntpd[20257]: ntp_io: estimated max descriptors: 1024, initial socket boundary: 16Jul 24 11:58:03 vm01 ntpd[20257]: Listen and drop on 0 v4wildcard 0.0.0.0 UDP 123Jul 24 11:58:03 vm01 ntpd[20257]: Listen and drop on 1 v6wildcard :: UDP 123Jul 24 11:58:03 vm01 ntpd[20257]: Listen normally on 2 lo 127.0.0.1 UDP 123Jul 24 11:58:03 vm01 ntpd[20257]: Listen normally on 3 ens33 192.168.133.3 UDP 123Jul 24 11:58:03 vm01 ntpd[20257]: Listen normally on 4 lo ::1 UDP 123Jul 24 11:58:03 vm01 ntpd[20257]: Listen normally on 5 ens33 fe80::1a15:8411:8d59:624e UDP 123Jul 24 11:58:03 vm01 ntpd[20257]: Listening on routing socket on fd #22 for interface updates 配置ntp参数 内网环境，无法连通外网。主节点这里使用date -s调整时间【安装系统时设置时间】，ntp设为与本地同步从节点设置与主节点同步目的：保障集群各节点时间相同即可 【如果集群中某台机器可以连接外网，则设置此集群为ntp服务器，其他机器与此机器进行ntp时间同步】 主节点： 12345678910111213141516171819202122232425262728[root@vm01 ~]# vi /etc/ntp.conf# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1restrict ::1# Hosts on local network are less restricted.#允许内网其他机器同步时间restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst#设置与本地时间同步server 127.127.1.0 preferfudge 127.127.1.0 stratum 10#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client 查看： 1234[root@vm01 ~]# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*LOCAL(0) .LOCL. 5 l 19 64 77 0.000 0.000 0.000 从节点： 123456789101112131415161718192021222324252627[root@vm02 ~]# vi /etc/ntp.confrestrict 127.0.0.1restrict ::1# Hosts on local network are less restricted.#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst#设置与主节点ip同步server 192.168.133.3 prefer#设置副设置与本地同步server 127.127.1.0fudge 127.127.1.0 stratum 10#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client 查看： 12345[root@vm03 ntp]# ntpq -p remote refid st t when poll reach delay offset jitter============================================================================== vm01 LOCAL(0) 11 u 26 64 1 0.297 9.103 0.000*LOCAL(0) .LOCL. 10 l 25 64 1 0.000 0.000 0.000 5.修改yum源，增加HDP的yum源安装httpd服务器上传，安装，启动，设置开机自启 12345678910111213141516171819202122232425262728293031323334353637383940[root@vm01 httpd]# lltotal 3100-rw-r--r--. 1 root root 105728 Aug 15 11:59 apr-1.4.8-3.el7_4.1.x86_64.rpm-rw-r--r--. 1 root root 94132 Aug 15 11:59 apr-util-1.5.2-6.el7.x86_64.rpm-rw-r--r--. 1 root root 2844220 Aug 15 10:08 httpd-2.4.6-89.el7.centos.x86_64.rpm-rw-r--r--. 1 root root 92616 Aug 15 10:08 httpd-tools-2.4.6-89.el7.centos.x86_64.rpm-rw-r--r--. 1 root root 31264 Aug 15 11:59 mailcap-2.1.41-2.el7.noarch.rpm[root@vm01 httpd]# pwd/opt/apps/httpd[root@vm01 httpd]# rpm -ivh apr-1.4.8-3.el7_4.1.x86_64.rpmwarning: apr-1.4.8-3.el7_4.1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:apr-1.4.8-3.el7_4.1 ################################# [100%][root@vm01 httpd]# rpm -ivh apr-util-1.5.2-6.el7.x86_64.rpmwarning: apr-util-1.5.2-6.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:apr-util-1.5.2-6.el7 ################################# [100%][root@vm01 httpd]# rpm -ivh mailcap-2.1.41-2.el7.noarch.rpmwarning: mailcap-2.1.41-2.el7.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:mailcap-2.1.41-2.el7 ################################# [100%][root@vm01 httpd]# rpm -ivh httpd-tools-2.4.6-89.el7.centos.x86_64.rpmwarning: httpd-tools-2.4.6-89.el7.centos.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:httpd-tools-2.4.6-89.el7.centos ################################# [100%][root@vm01 httpd]# rpm -ivh httpd-2.4.6-89.el7.centos.x86_64.rpmwarning: httpd-2.4.6-89.el7.centos.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:httpd-2.4.6-89.el7.centos ################################# [100%][root@vm01 httpd]# systemctl start httpd[root@vm01 httpd]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. HDP安装包上传至/var/www/html文件夹12345678[root@vm01 ambari]# lltotal 8949860-rw-r--r--. 1 root root 1823779835 Jul 23 18:26 ambari-2.6.2.2-centos7.tar.gz-rw-r--r--. 1 root root 7249933344 Jul 23 18:24 HDP-2.6.5.0-centos7-rpm.tar.gz-rw-r--r--. 1 root root 328623 Jul 23 18:24 HDP-GPL-2.6.5.0-centos7-gpl.tar.gz-rw-r--r--. 1 root root 90606616 Jul 23 18:24 HDP-UTILS-1.1.0.22-centos7.tar.gz[root@vm01 ambari]# pwd/var/www/html/ambari 解压： 1234[root@vm01 ambari]# tar -zxvf ambari-2.6.2.2-centos7.tar.gz[root@vm01 ambari]# tar -zxvf HDP-2.6.5.0-centos7-rpm.tar.gz[root@vm01 ambari]# tar -zxvf HDP-GPL-2.6.5.0-centos7-gpl.tar.gz[root@vm01 ambari]# tar -zxvf HDP-UTILS-1.1.0.22-centos7.tar.gz 删除： 1234[root@vm01 ambari]# rm -rf ambari-2.6.2.2-centos7.tar.gz[root@vm01 ambari]# rm -rf HDP-2.6.5.0-centos7-rpm.tar.gz[root@vm01 ambari]# rm -rf HDP-GPL-2.6.5.0-centos7-gpl.tar.gz[root@vm01 ambari]# rm -rf HDP-UTILS-1.1.0.22-centos7.tar.gz 访问：http://192.168.133.3/ambari/ 查看是否成功 制作hdp本地源上传，安装 12345678910111213141516171819202122232425[root@vm01 yum]# pwd/opt/apps/yum[root@vm01 yum]# lltotal 244-rw-r--r-- 1 root root 95840 Aug 10 2017 createrepo-0.9.9-28.el7.noarch.rpm-rw-r--r-- 1 root root 83984 Jul 4 2014 deltarpm-3.6-3.el7.x86_64.rpm-rw-r--r-- 1 root root 32084 Jul 4 2014 python-deltarpm-3.6-3.el7.x86_64.rpm-rw-r--r-- 1 root root 29388 Nov 12 2018 yum-plugin-priorities-1.1.31-50.el7.noarch.rpm[root@vm01 yum]# rpm -ivh deltarpm-3.6-3.el7.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:deltarpm-3.6-3.el7 ################################# [100%][root@vm01 yum]# rpm -ivh python-deltarpm-3.6-3.el7.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:python-deltarpm-3.6-3.el7 ################################# [100%][root@vm01 yum]# rpm -ivh createrepo-0.9.9-28.el7.noarch.rpmPreparing... ################################# [100%]Updating / installing... 1:createrepo-0.9.9-28.el7 ################################# [100%][root@vm01 yum]# rpm -ivh yum-plugin-priorities-1.1.31-50.el7.noarch.rpmPreparing... ################################# [100%]Updating / installing... 1:yum-plugin-priorities-1.1.31-50.e################################# [100%] 12345678[root@vm01 yum]# createrepo ./Spawning worker 0 with 4 pkgsWorkers FinishedSaving Primary metadataSaving file lists metadataSaving other metadataGenerating sqlite DBsSqlite DBs complete 修改源的地址123456789101112131415161718192021222324252627282930[root@vm01 yum]# vi /var/www/html/ambari/ambari/centos7/2.6.2.2-1/ambari.repo#VERSION_NUMBER=2.6.2.2-1[ambari-2.6.2.2]name=ambari Version - ambari-2.6.2.2baseurl=http://192.168.133.3/ambari/ambari/centos7/2.6.2.2-1/gpgcheck=1gpgkey=http://192.168.133.3/ambari/ambari/centos7/2.6.2.2-1/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1[root@vm01 yum]# cp /var/www/html/ambari/ambari/centos7/2.6.2.2-1/ambari.repo /etc/yum.repos.d/[root@vm01 yum]# vi /var/www/html/ambari/HDP/centos7/2.6.5.0-292/hdp.repo#VERSION_NUMBER=2.6.5.0-292[HDP-2.6.5.0]name=HDP Version - HDP-2.6.5.0baseurl=http://192.168.133.3/ambari/HDP/centos7/2.6.5.0-292/gpgcheck=1gpgkey=http://192.168.133.3/ambari/HDP/centos7/2.6.5.0-292/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1[HDP-UTILS-1.1.0.22]name=HDP-UTILS Version - HDP-UTILS-1.1.0.22baseurl=http://192.168.133.3/ambari/HDP/centos7/2.6.5.0-292/gpgcheck=1gpgkey=http://192.168.133.3/ambari/HDP/centos7/2.6.5.0-292/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1[root@vm01 yum]# cp /var/www/html/ambari/HDP/centos7/2.6.5.0-292/hdp.repo /etc/yum.repos.d/ 将ambari.repo；hdp.repo源拷贝到其他节点 12345678[root@vm01 yum]# scp /etc/yum.repos.d/ambari.repo vm02:/etc/yum.repos.d/ambari.repo 100% 267 248.2KB/s 00:00[root@vm01 yum]# scp /etc/yum.repos.d/ambari.repo vm03:/etc/yum.repos.d/ambari.repo 100% 267 117.9KB/s 00:00[root@vm01 yum]# scp /etc/yum.repos.d/hdp.repo vm03:/etc/yum.repos.d/hdp.repo 100% 508 422.7KB/s 00:00[root@vm01 yum]# scp /etc/yum.repos.d/hdp.repo vm02:/etc/yum.repos.d/hdp.repo 100% 508 451.1KB/s 00:00 6.安装ambari-sever【以mysql为数据库安装】安装mysql【系统如果为迷你版，则部分组件没有被安装，再次安装时需要联网进行】注意：linux系统为最小化安装，通过下载官网压缩包离线安装时，还需要系统方面的某些小依赖包。导致mysql离线安装失败linux系统为虚拟化主机或者桌面版就可以直接安装 系统为虚拟化主机版本：上传官网的压缩包，解压，按照顺序安装 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost mysql_5.7.27]# ll总用量 1037224-rw-r--r--. 1 root root 531056640 7月 24 16:09 mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar-rw-r--r--. 1 7155 31415 25365436 6月 12 14:42 mysql-community-client-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 281248 6月 12 14:42 mysql-community-common-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 3833396 6月 12 14:42 mysql-community-devel-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 47074656 6月 12 14:42 mysql-community-embedded-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 24079736 6月 12 14:42 mysql-community-embedded-compat-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 129991352 6月 12 14:42 mysql-community-embedded-devel-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 2272032 6月 12 14:42 mysql-community-libs-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 2116432 6月 12 14:42 mysql-community-libs-compat-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 173500088 6月 12 14:43 mysql-community-server-5.7.27-1.el7.x86_64.rpm-rw-r--r--. 1 7155 31415 122530756 6月 12 14:43 mysql-community-test-5.7.27-1.el7.x86_64.rpm#删除mariadb，否则会有冲突[root@vm01 mysql]# rpm -qa | grep mariadbmariadb-libs-5.5.56-2.el7.x86_64[root@vm01 mysql]# rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64#安装mysql，按照顺序[root@localhost mysql_5.7.27]# rpm -ivh mysql-community-common-5.7.27-1.el7.x86_64.rpm警告：mysql-community-common-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mysql-community-common-5.7.27-1.e################################# [100%][root@localhost mysql_5.7.27]# rpm -ivh mysql-community-libs-5.7.27-1.el7.x86_64.rpm警告：mysql-community-libs-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mysql-community-libs-5.7.27-1.el7################################# [100%][root@localhost mysql_5.7.27]# rpm -ivh mysql-community-client-5.7.27-1.el7.x86_64.rpm警告：mysql-community-client-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mysql-community-client-5.7.27-1.e################################# [100%][root@localhost mysql_5.7.27]# rpm -ivh mysql-community-server-5.7.27-1.el7.x86_64.rpm警告：mysql-community-server-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mysql-community-server-5.7.27-1.e################################# [100%] 启动，设置开机自启123456789101112131415161718[root@vm01 mysql_5.7.27]# systemctl start mysqld[root@vm01 mysql_5.7.27]# systemctl enable mysqld[root@vm01 mysql_5.7.27]# systemctl status mysqld● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2019-07-24 16:22:28 CST; 15s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Main PID: 11260 (mysqld) CGroup: /system.slice/mysqld.service └─11260 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pidJul 24 16:22:25 vm01 systemd[1]: Starting MySQL Server...Jul 24 16:22:28 vm01 systemd[1]: Started MySQL Server.[root@vm01 mysql_5.7.27]# vi /etc/rc.local#增加systemctl start mysqld 获取临时密码登录mysql，设置密码，设置远程登录12345[root@vm01 mysql_5.7.27]# grep 'temporary password' /var/log/mysqld.log2019-07-24T08:22:25.615573Z 1 [Note] A temporary password is generated for root@localhost: 8BdMN2JWj*q&gt;[root@vm01 mysql_5.7.27]# mysql -uroot -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \g. 123456789101112131415#设置mysql登录密码为123456mysql&gt; alter user 'root'@'localhost' identified by '123456';ERROR 1819 (HY000): Your password does not satisfy the current policy requirements#出错，密码不符合mysql的安全策略，降低mysql的全局密码验证策略mysql&gt; set global validate_password_policy=0;Query OK, 0 rows affected (0.00 sec)#设置密码长度mysql&gt; set global validate_password_length=6;Query OK, 0 rows affected (0.00 sec)#设置密码为123456mysql&gt; alter user 'root'@'localhost' identified by '123456';Query OK, 0 rows affected (0.00 sec) 设置远程登录 12345mysql&gt; grant all privileges on *.* to 'root'@'%' identified by '123456';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) 安装postgresql123456789101112131415161718[root@vm01 postgresql]# lltotal 7256-rw-r--r-- 1 root root 3175716 Aug 24 2018 postgresql-9.2.24-1.el7_5.x86_64.rpm-rw-r--r-- 1 root root 239640 Aug 24 2018 postgresql-libs-9.2.24-1.el7_5.x86_64.rpm-rw-r--r-- 1 root root 4006220 Aug 24 2018 postgresql-server-9.2.24-1.el7_5.x86_64.rpm[root@vm01 postgresql]# rpm -ivh postgresql-libs-9.2.24-1.el7_5.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:postgresql-libs-9.2.24-1.el7_5 ################################# [100%][root@vm01 postgresql]# rpm -ivh postgresql-9.2.24-1.el7_5.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:postgresql-9.2.24-1.el7_5 ################################# [100%][root@vm01 postgresql]# rpm -ivh postgresql-server-9.2.24-1.el7_5.x86_64.rpmPreparing... ################################# [100%]Updating / installing... 1:postgresql-server-9.2.24-1.el7_5 ################################# [100%] 安装ambari-server123456789101112131415[root@vm01 yum.repos.d]# lltotal 40-rw-r--r--. 1 root root 267 Aug 15 13:40 ambari.repo-rw-r--r--. 1 root root 1664 Apr 29 2018 CentOS-Base.repo-rw-r--r--. 1 root root 1309 Apr 29 2018 CentOS-CR.repo-rw-r--r--. 1 root root 649 Apr 29 2018 CentOS-Debuginfo.repo-rw-r--r--. 1 root root 314 Apr 29 2018 CentOS-fasttrack.repo-rw-r--r--. 1 root root 630 Apr 29 2018 CentOS-Media.repo-rw-r--r--. 1 root root 1331 Apr 29 2018 CentOS-Sources.repo-rw-r--r--. 1 root root 4768 Apr 29 2018 CentOS-Vault.repo-rw-r--r--. 1 root root 514 Aug 15 13:42 hdp.repo#yum默认使用的是base网络源，将其改名。离线状态下将其mv掉，使用我们自己的yum源[root@vm01 yum.repos.d]# mv CentOS-Base.repo CentOS-Base.repo_bak[root@vm01 yum.repos.d]# yum -y install ambari-server 登录mysql，执行以下语句1234567891011121314151617181920212223242526272829303132333435CREATE DATABASE ambari; use ambari; CREATE USER 'ambari'@'%' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'%'; CREATE USER 'ambari'@'localhost' IDENTIFIED BY '123456';GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'localhost'; CREATE USER 'ambari'@'master' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'master'; FLUSH PRIVILEGES; source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql show tables; use mysql; select Host,User Password from user where user='ambari'; CREATE DATABASE hive; use hive; CREATE USER 'hive'@'%' IDENTIFIED BY '123456';GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%'; CREATE USER 'hive'@'localhost' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'hive'@'localhost'; CREATE USER 'hive'@'master' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'hive'@'master'; FLUSH PRIVILEGES; CREATE DATABASE oozie; use oozie; CREATE USER 'oozie'@'%' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'%'; CREATE USER 'oozie'@'localhost' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'localhost';CREATE USER 'oozie'@'master' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'master';FLUSH PRIVILEGES; 建立mysql和ambari-server的连接上传mysql-connection-java-5.1.40.tar.gz包，解压 123456789101112131415161718192021[root@vm01 mysql_connect]# lltotal 4348drwxr-xr-x 3 root root 178 Aug 7 2018 mysql-connector-java-5.1.47-rw-r--r-- 1 root root 4452049 Jul 24 17:03 mysql-connector-java-5.1.47.tar.gz[root@vm01 mysql_connect]# cd mysql-connector-java-5.1.47[root@vm01 mysql-connector-java-5.1.47]# lltotal 2448-rw-r--r-- 1 root root 91845 Aug 7 2018 build.xml-rw-r--r-- 1 root root 248527 Aug 7 2018 CHANGES-rw-r--r-- 1 root root 18122 Aug 7 2018 COPYING-rw-r--r-- 1 root root 1007505 Aug 7 2018 mysql-connector-java-5.1.47-bin.jar-rw-r--r-- 1 root root 1007502 Aug 7 2018 mysql-connector-java-5.1.47.jar-rw-r--r-- 1 root root 61407 Aug 7 2018 README-rw-r--r-- 1 root root 63658 Aug 7 2018 README.txtdrwxr-xr-x 8 root root 79 Aug 7 2018 src[root@vm01 mysql-connector-java-5.1.47]# mkdir /usr/share/java[root@vm01 mysql-connector-java-5.1.47]# cp mysql-connector-java-5.1.47.jar /usr/share/java/mysql-connector-java.jar[root@vm01 mysql-connector-java-5.1.47]# cp /usr/share/java/mysql-connector-java.jar /var/lib/ambari-server/resources/mysql-jdbc-driver.jar[root@vm01 mysql-connector-java-5.1.47]# vi /etc/ambari-server/conf/ambari.properties#增加server.jdbc.driver.path=/usr/share/java/mysql-connector-java.jar 初始化设置ambari-server12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@vm01 mysql_5.7.27]# ambari-server setupUsing python /usr/bin/pythonSetup ambari-serverChecking SELinux...SELinux status is 'disabled'Customize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):Adjusting ambari-server permissions and ownership...Checking firewall status...Checking JDK...[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7[3] Custom JDK==============================================================================#自定义jdk位置Enter choice (1): 3WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.Path to JAVA_HOME: /opt/apps/jdk/jdk1.8.0_144Validating JDK on Ambari Server...done.Checking GPL software agreement...GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.htmlEnable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? yCompleting setup...Configuring database...Enter advanced database configuration [y/n] (n)? yConfiguring database...==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle[3] - MySQL / MariaDB[4] - PostgreSQL[5] - Microsoft SQL Server (Tech Preview)[6] - SQL Anywhere[7] - BDB==============================================================================#选择ambari储存的数据库为mysqlEnter choice (1): 3#设置数据库的配置信息，括号内为默认，可以更改Hostname (localhost): vm01Port (3306):Database name (ambari):Username (ambari):Enter Database Password (bigdata):Re-enter password:Configuring ambari database...Configuring remote database connection properties...WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sqlProceed with configuring remote database connection properties [y/n] (y)? yExtracting system views...ambari-admin-2.6.2.2.1.jar...........Adjusting ambari-server permissions and ownership...Ambari Server 'setup' completed successfully. 启动ambari1234567891011[root@vm01 mysql_5.7.27]# ambari-server startUsing python /usr/bin/pythonStarting ambari-serverAmbari Server running with administrator privileges.Organizing resource files at /var/lib/ambari-server/resources...Ambari database consistency check started...Server PID at: /var/run/ambari-server/ambari-server.pidServer out at: /var/log/ambari-server/ambari-server.outServer log at: /var/log/ambari-server/ambari-server.logWaiting for server start............................................................ERROR: Exiting with exit code 1.REASON: Server not yet listening on http port 8080 after 50 seconds. Exiting. 如果没有启动成功，修改等待时间： 1234567891011121314151617181920[root@vm01 mysql_5.7.27]# vi /etc/ambari-server/conf/ambari.properties#增加server.startup.web.timeout=120[root@vm01 mysql_5.7.27]# ambari-server restartUsing python /usr/bin/pythonRestarting ambari-serverWaiting for server stop...Ambari Server stoppedAmbari Server running with administrator privileges.Organizing resource files at /var/lib/ambari-server/resources...Ambari database consistency check started...Server PID at: /var/run/ambari-server/ambari-server.pidServer out at: /var/log/ambari-server/ambari-server.outServer log at: /var/log/ambari-server/ambari-server.logWaiting for server start.......................Server started listening on 8080DB configs consistency check: no errors and warnings were found. 7.错误处理如果在安装过程中出现一些问题，则将一切都回滚清除，重新设置注意：最好删除mysql中创建的数据库，然后mysql中user表创建的用户【重新设置时需要从上面的步骤重新导入】 123[root@vm01 mysql_5.7.27]# ambari-server stop[root@vm01 mysql_5.7.27]# ambari-server reset[root@vm01 mysql_5.7.27]# ambari-server setup 8.安装HDP集群组件登录：http://192.168.133.3:8080/#/login用户名，密码：admin依照安装向导进行设置 安装向导：点击launch install wizard 输入集群名称 设置版本，设置本地仓库地址 设置主机名，配置id_rsa 完成免密登录配置后，将id_rsa文件下载到本地 1234567[root@vm01 ssh]# cd ~/.ssh/[root@vm01 .ssh]# lltotal 16-rw-------. 1 root root 391 Aug 15 10:20 authorized_keys-rw-------. 1 root root 1679 Aug 15 10:19 id_rsa-rw-r--r--. 1 root root 391 Aug 15 10:19 id_rsa.pub-rw-r--r--. 1 root root 540 Aug 15 10:21 known_hosts 完成配置 选择组件 选择组件安装位置 选择slaves和clients 配置参数 配置hive时注意： 1234567[root@vm01 .ssh]# ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jarUsing python /usr/bin/pythonSetup ambari-serverCopying /usr/share/java/mysql-connector-java.jar to /var/lib/ambari-server/resourcesIf you are updating existing jdbc driver jar for mysql with mysql-connector-java.jar. Please remove the old driver jar, from all hosts. Restarting services that need the driver, will automatically copy the new jar to the hosts.JDBC driver was successfully initialized.Ambari Server 'setup' completed successfully. 一路点击完成下一步即可]]></content>
      <categories>
        <category>大数据</category>
        <category>HDP</category>
      </categories>
      <tags>
        <tag>HDP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
